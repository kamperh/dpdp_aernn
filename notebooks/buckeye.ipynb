{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation on Buckeye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2021 Herman Kamper, MIT License\n",
    "\n",
    "Train a segmental autoencoding recurrent neural network (segmental AE-RNN) and perform word segmentation on encoded Buckeye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy.stats import gamma\n",
    "from sklearn import cluster\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from seg_aernn import datasets, models, viterbi\n",
    "from utils import eval_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented_sentence(ids, boundaries):\n",
    "    output = \"\"\n",
    "    cur_word = []\n",
    "    for i_symbol, boundary in enumerate(boundaries):\n",
    "        cur_word.append(id_to_symbol[ids[i_symbol]])\n",
    "        if boundary:\n",
    "            output += \"_\".join(cur_word)\n",
    "            output += \" \"\n",
    "            cur_word = []\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration penalty functions\n",
    "\n",
    "# Histogram\n",
    "histogram = np.array([\n",
    "    0, 1.66322800e-01, 2.35838129e-01, 2.10609187e-01,\n",
    "    1.48025482e-01, 9.42918160e-02, 5.84211098e-02, 3.64679480e-02,\n",
    "    2.18264741e-02, 1.25420784e-02, 7.18500018e-03, 4.27118399e-03,\n",
    "    1.73743077e-03, 1.19448366e-03, 7.42027726e-04, 2.89571796e-04,\n",
    "    2.35277084e-04, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001\n",
    "    ])  # to-do: check this\n",
    "histogram = histogram/np.sum(histogram)\n",
    "def neg_log_hist(dur):\n",
    "    return -np.log(0 if dur >= len(histogram) else histogram[dur])\n",
    "\n",
    "# Cached Gamma\n",
    "# shape, loc, scale = (2.3, 0, 1.3)  # VQ-VAE\n",
    "shape, loc, scale = (2.6, 0, 1.8)    # CPC-big\n",
    "# shape, loc, scale = (2.5, 0, 1.5)    # CPC-big (Gamma)\n",
    "gamma_cache = []\n",
    "for dur in range(200):\n",
    "    gamma_cache.append(gamma.pdf(dur, shape, loc, scale))\n",
    "gamma_cache = np.array(gamma_cache)/np.sum(gamma_cache)\n",
    "def neg_log_gamma(dur):\n",
    "    if dur < 200:\n",
    "        return -np.log(gamma_cache[dur])\n",
    "    else:\n",
    "        return -np.log(0)\n",
    "    \n",
    "# Chorowski\n",
    "def neg_chorowski(dur):\n",
    "    return -(dur - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "vq_model = \"gmm\"\n",
    "# vq_model = \"cpc_big\"\n",
    "# vq_model = \"cpc_big_normalized\"\n",
    "# vq_model = \"xlsr\"\n",
    "dataset = \"buckeye\"\n",
    "split = \"val\"\n",
    "# seg_tag = \"phoneseg_dp_penalized\"\n",
    "seg_tag = \"phoneseg_dp_penalized_25\"\n",
    "# seg_tag = \"phoneseg_dp_penalized_tune\"\n",
    "\n",
    "# Paths\n",
    "seg_dir = (\n",
    "    Path(\"../../vqwordseg/exp\")/vq_model/dataset/split/seg_tag/\"intervals\"\n",
    "    )\n",
    "word_ref_dir = Path(\"../../vqwordseg/data\")/dataset/\"word_intervals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1755/16355 [00:00<00:00, 17547.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../../vqwordseg/exp/gmm/buckeye/val/phoneseg_dp_penalized_25/intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16355/16355 [00:00<00:00, 17663.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read phone segmentation\n",
    "phoneseg_interval_dict = {}\n",
    "print(\"Reading: {}\".format(seg_dir))\n",
    "phoneseg_interval_dict = eval_segmentation.get_intervals_from_dir(seg_dir)\n",
    "utterances = phoneseg_interval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 3654/16355 [00:00<00:00, 36521.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../../vqwordseg/data/buckeye/word_intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16355/16355 [00:00<00:00, 36415.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read word reference\n",
    "print(\"Reading: {}\".format(word_ref_dir))\n",
    "word_ref_interval_dict = eval_segmentation.get_intervals_from_dir(word_ref_dir, utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16355/16355 [00:00<00:00, 986536.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. word types: 4057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_types = set()\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    for start, end, label in word_ref_interval_dict[utt_key]:\n",
    "        word_types.add(label)\n",
    "print(\"No. word types:\", len(word_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16355/16355 [00:00<00:00, 303241.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert intervals to boundaries\n",
    "word_ref_boundaries_dict = {}\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    word_ref_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        word_ref_interval_dict[utt_key]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16355/16355 [00:00<00:00, 457325.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23_6_15_4_19_20_9_0_23_8_2_8_21_11_16_4_7_19_9_2_8_6_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepared_text = []\n",
    "for utt_key in tqdm(utterances):\n",
    "    prepared_text.append(\n",
    "        \"_\".join([i[2] for i in phoneseg_interval_dict[utt_key]])\n",
    "        )\n",
    "    \n",
    "print(prepared_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16355/16355 [00:00<00:00, 21659.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23_6_15_4_19_20_9 0_23_8_2_8_21_11_16_4_7_19_9_2_8 6_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gold segmentation, where boundaries are inserted in best possible positions\n",
    "n_not_in_tolerance = 0\n",
    "prepared_text_gold = []\n",
    "for utt_key in tqdm(utterances):\n",
    "    seg_intervals = phoneseg_interval_dict[utt_key].copy()\n",
    "    ref_intervals = word_ref_interval_dict[utt_key].copy()\n",
    "    seg_boundaries = np.array([i[1] - 1 for i in seg_intervals])\n",
    "    ref_boundaries = np.array([i[1] - 1 for i in ref_intervals])\n",
    "    for ref_boundary in ref_boundaries[:-1]:\n",
    "        i_seg = np.argmin(np.abs(seg_boundaries - ref_boundary))\n",
    "        seg_intervals.insert(\n",
    "            i_seg + 1, (seg_intervals[i_seg][1], seg_intervals[i_seg][1], \" \")\n",
    "            )\n",
    "        seg_boundaries = np.array([i[1] - 1 for i in seg_intervals])\n",
    "    cur_text_gold = \"\"\n",
    "    for start, end, label in seg_intervals:\n",
    "        if label == \" \":\n",
    "            cur_text_gold = cur_text_gold[:-1]\n",
    "            cur_text_gold += \" \"\n",
    "        else:\n",
    "            cur_text_gold += label + \"_\"\n",
    "    cur_text_gold = cur_text_gold[:-1]\n",
    "    prepared_text_gold.append(cur_text_gold)\n",
    "\n",
    "print(prepared_text_gold[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. word types: 45150\n",
      "Mean training word length: 8.2542\n",
      "Min training word length:  1\n",
      "Max training word length:  50\n",
      "Mean: 8.25418775393827\n",
      "Gamma parameters: 2.332450230163011 0 3.5388483952180185\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training word length statistics\n",
    "word_lengths = []\n",
    "n_words = []\n",
    "word_types = set()\n",
    "for sentence in prepared_text_gold:\n",
    "    word_lengths.extend([len(i.split(\"_\")) for i in sentence.split(\" \")])\n",
    "    n_words.append(len(sentence.split(\" \")))\n",
    "    for word in sentence.split(\" \"):\n",
    "        word_types.add(word)\n",
    "#     word_lengths.extend([len(i.replace(\"$\", \"\")) for i in sentence.split(\" \")])  # temp\n",
    "print(\"No. word types:\", len(word_types))\n",
    "print(\"Mean training word length: {:.4f}\".format(np.mean(word_lengths)))\n",
    "print(\"Min training word length:  {:d}\".format(np.min(word_lengths)))\n",
    "print(\"Max training word length:  {:d}\".format(np.max(word_lengths)))\n",
    "\n",
    "# Histogram\n",
    "plt.figure()\n",
    "n, bins, patches = plt.hist(word_lengths, bins=range(20), density=True)\n",
    "plt.title(\"Word lengths\")\n",
    "\n",
    "# Gamma\n",
    "mean = np.mean(word_lengths)\n",
    "var  = np.var(word_lengths)\n",
    "alpha = (mean**2)/var\n",
    "beta  = alpha / mean\n",
    "shape = alpha\n",
    "loc = 0\n",
    "scale = 1/beta\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Gamma parameters:\", shape, loc, scale)\n",
    "shape, loc, scale = (2.6, 0, 1.8)\n",
    "plt.plot(bins, gamma.pdf(bins, shape, loc, scale))\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 25, 11, 23, 15, 17, 28, 4, 20, 27, 16, 27, 18, 7, 12, 23, 26, 15, 28, 16, 27, 25, 26]\n",
      "['23', '6', '15', '4', '19', '20', '9', '0', '23', '8', '2', '8', '21', '11', '16', '4', '7', '19', '9', '2', '8', '6', '7']\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary\n",
    "PAD_SYMBOL      = \"<pad>\"\n",
    "SOS_SYMBOL      = \"<s>\"    # start of sentence\n",
    "EOS_SYMBOL      = \"</s>\"   # end of sentence\n",
    "BOUNDARY_SYMBOL = \" \"      # word boundary\n",
    "symbols = set()\n",
    "for sentence in prepared_text:\n",
    "    for char in sentence.split(\"_\"):\n",
    "        symbols.add(char)\n",
    "SYMBOLS = [PAD_SYMBOL, SOS_SYMBOL, EOS_SYMBOL, BOUNDARY_SYMBOL] + (sorted(list(symbols)))\n",
    "symbol_to_id = {s: i for i, s in enumerate(SYMBOLS)}\n",
    "id_to_symbol = {i: s for i, s in enumerate(SYMBOLS)}\n",
    "\n",
    "def text_to_id(text, add_sos_eos=False):\n",
    "    \"\"\"\n",
    "    Convert text to a list of symbol IDs.\n",
    "\n",
    "    Sentence start and end symbols can be added by setting `add_sos_eos`.\n",
    "    \"\"\"\n",
    "    symbol_ids = []\n",
    "    for word in text.split(\" \"):\n",
    "        for code in word.split(\"_\"):\n",
    "            symbol_ids.append(symbol_to_id[code])\n",
    "        symbol_ids.append(symbol_to_id[BOUNDARY_SYMBOL])\n",
    "    symbol_ids = symbol_ids[:-1]  # remove last space\n",
    "\n",
    "    if add_sos_eos:\n",
    "        return [symbol_to_id[SOS_SYMBOL]] + symbol_ids + [symbol_to_id[EOS_SYMBOL]]\n",
    "    else:\n",
    "        return symbol_ids\n",
    "\n",
    "print(text_to_id(prepared_text[0]))\n",
    "print([id_to_symbol[i] for i in text_to_id(prepared_text[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23_6_15_4_19_20_9_0_23_8_2_8_21_11_16_4_7_19_9_2_8_6_7\n",
      "12_14_24_18_1_10_17_22_15_12_2\n",
      "5_15_3_13_22_15_2_4_3_1_13_14_5_22_1_17_22_15_12_4_5_3_1_13_17_22_15_2_21_4_5_0_20_5_21_17_11\n",
      "23_17_22_15_2_11_3_7_4_7_0_8_5_6_7_22_0_5_15_6_2_4\n",
      "23_6_7_19_8_22_1_7_19_9_8_2_6_3_7_19_9_8_1_7_19_9_0_8_9_3_10_5_20_8_17_22_15_2_7_16_9_8_1_7\n",
      "23_6_4_3_5_17_6_15_18_12_7_5_0_24_19_9_8_6_3_7_19_9\n",
      "23_24_6_11_18_12_19_9_10_0_24_8_6_2_4_7_4_10_0_24_21_1_21_2_11_3_13_14_17_22_15_4_19_0_24_9_3_24_18_24_1_18_15_12_19_20_9_20_0_24_9_10\n"
     ]
    }
   ],
   "source": [
    "# First three words of training data\n",
    "word_dataset = datasets.WordDataset(prepared_text, text_to_id)\n",
    "for i in range(7):\n",
    "    sample = word_dataset[i]\n",
    "    print(\"_\".join([id_to_symbol[i] for i in sample.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. train sentences: 16355\n",
      "Examples: ['23_6_15_4_19_20_9_0_23_8_2_8_21_11_16_4_7_19_9_2_8_6_7', '12_14_24_18_1_10_17_22_15_12_2', '5_15_3_13_22_15_2_4_3_1_13_14_5_22_1_17_22_15_12_4_5_3_1_13_17_22_15_2_21_4_5_0_20_5_21_17_11']\n",
      "Min length:  1\n",
      "Max length:  247\n",
      "Mean length: 28.3211\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "# Approximate ground truth (for debugging)\n",
    "# cur_train_sentences = prepared_text_gold[:10000]\n",
    "cur_val_sentences = prepared_text_gold[-1000:]\n",
    "\n",
    "# No boundaries\n",
    "# cur_train_sentences = prepared_text[:10000]\n",
    "cur_train_sentences = prepared_text\n",
    "\n",
    "# Random boundaries\n",
    "np.random.seed(42)\n",
    "# cur_train_sentences = insert_random_boundaries(cur_train_sentences)\n",
    "# cur_val_sentences = insert_random_boundaries(cur_val_sentences)\n",
    "\n",
    "print(\"No. train sentences:\", len(cur_train_sentences))\n",
    "print(\"Examples:\", cur_train_sentences[:3])\n",
    "print(\"Min length: \", min([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Max length: \", max([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Mean length: {:.4f}\".format(np.mean([len(i.split(\"_\")) for i in cur_train_sentences])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(i.split(\"_\")) for i in cur_train_sentences], 100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE-RNN model\n",
    "n_symbols = len(SYMBOLS)\n",
    "symbol_embedding_dim = 10  # 25\n",
    "hidden_dim = 500  # 250  # 500  # 1000  # 200\n",
    "embedding_dim = 50  # 150  # 300  # 25\n",
    "teacher_forcing_ratio = 0.5  # 1.0  # 0.5  # 1.0\n",
    "n_encoder_layers = 1  # 1  # 3  # 10\n",
    "n_decoder_layers = 1  # 1  # 1\n",
    "batch_size = 32  # 32*3  # 32\n",
    "learning_rate = 0.001\n",
    "input_dropout = 0.0  # 0.0 # 0.5\n",
    "dropout = 0.0\n",
    "n_symbols_max = 50  # 25\n",
    "# n_epochs_max = 5\n",
    "n_epochs_max = None  # determined from n_max_steps and batch size\n",
    "n_steps_max = 1500  # 2500  # 1500  # 1000  # None\n",
    "# n_steps_max = None  # Only use n_epochs_max\n",
    "bidirectional_encoder = False  # False\n",
    "\n",
    "encoder = models.Encoder(\n",
    "    n_symbols=n_symbols,\n",
    "    symbol_embedding_dim=symbol_embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_encoder_layers,\n",
    "    dropout=dropout,\n",
    "    input_dropout=input_dropout,\n",
    "    bidirectional=bidirectional_encoder\n",
    "    )\n",
    "# decoder = models.Decoder1(\n",
    "#     n_symbols=n_symbols,\n",
    "#     symbol_embedding_dim=symbol_embedding_dim,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     n_layers=n_decoder_layers,\n",
    "#     sos_id = symbol_to_id[SOS_SYMBOL],\n",
    "#     teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "#     dropout=dropout\n",
    "#     )\n",
    "decoder = models.Decoder2(\n",
    "    n_symbols=n_symbols,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_decoder_layers,\n",
    "    dropout=dropout\n",
    "    )\n",
    "model = models.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:16<00:00, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 72.231, val loss: 18.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:16<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 63.552, val loss: 13.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 475/512 [00:15<00:01, 31.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 58.771, val loss: 11.885\n"
     ]
    }
   ],
   "source": [
    "# Training device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Training data\n",
    "train_dataset = datasets.WordDataset(\n",
    "    cur_train_sentences, text_to_id, n_symbols_max=n_symbols_max\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Validation data\n",
    "val_dataset = datasets.WordDataset(cur_val_sentences, text_to_id)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Loss\n",
    "criterion = nn.NLLLoss(\n",
    "    reduction=\"sum\", ignore_index=symbol_to_id[PAD_SYMBOL]\n",
    "    )\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "if n_epochs_max is None:\n",
    "    steps_per_epoch = np.ceil(len(cur_train_sentences)/batch_size)\n",
    "    n_epochs_max = int(np.ceil(n_steps_max/steps_per_epoch))\n",
    "\n",
    "i_step = 0\n",
    "for i_epoch in range(n_epochs_max):\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        optimiser.zero_grad()\n",
    "        data = data.to(device)       \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_output.contiguous().view(-1, decoder_output.size(-1)),\n",
    "            data.contiguous().view(-1)\n",
    "            )\n",
    "        loss /= len(data_lengths)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        train_losses.append(loss.item())\n",
    "        i_step += 1\n",
    "        if i_step == n_steps_max and n_steps_max is not None:\n",
    "            break\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "            data = data.to(device)            \n",
    "            encoder_embedding, decoder_output = model(\n",
    "                data, data_lengths, data, data_lengths\n",
    "                )\n",
    "\n",
    "            loss = criterion(\n",
    "                decoder_output.contiguous().view(-1,\n",
    "                decoder_output.size(-1)), data.contiguous().view(-1)\n",
    "                )\n",
    "            loss /= len(data_lengths)\n",
    "            val_losses.append(loss.item())\n",
    "    \n",
    "    print(\n",
    "        \"Epoch {}, train loss: {:.3f}, val loss: {:.3f}\".format(\n",
    "        i_epoch,\n",
    "        np.mean(train_losses),\n",
    "        np.mean(val_losses))\n",
    "        )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if i_step == n_steps_max and n_steps_max is not None:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  11_3_7_10_5_19_20\n",
      "Output: 11_3_3_10_5_19_19_20_20_20_20_10_10_10_10_10_10_10_10_10_10_10_10_10_10\n",
      "\n",
      "Input:  23_6_15_12_4_19_20_23\n",
      "Output: 23_6_15_12_4_19_20_23_23_23_23_23_23_23_23_23_23_23_23_23_23_23_23_23_23\n",
      "\n",
      "Input:  0_11_18_24_18_11_24_11_18_7_10_19_8_12_6_5\n",
      "Output: 18_18_11_11_11_18_18_18_12_7_19_20_8_6_6_11_18_10_10_10_5_5_5_10_10\n",
      "\n",
      "Input:  17_22_11_18\n",
      "Output: 17_22_11_18_18_18_18_18_18_18_18_18_18_18_18_18_18_18_18_18_18_18_18_18_18\n",
      "\n",
      "Input:  5_0_11_3_1_14_17\n",
      "Output: 0_0_11_3_1_14_17_17_17_14_10_10_10_10_14_14_14_14_14_14_14_14_14_14_14\n",
      "\n",
      "Input:  22_15_12\n",
      "Output: 22_22_12_12_12_12_10_10_12_12_12_12_12_12_12_12_12_12_12_12_12_12_12_12_12\n",
      "\n",
      "Input:  10_0_17_22_12_2_7_10_0\n",
      "Output: 0_17_17_15_12_2_4_10_0_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10\n",
      "\n",
      "Input:  11_16_4_5_0\n",
      "Output: 11_11_4_5_0_0_0_5_5_5_5_10_10_10_10_10_10_5_5_5_10_10_10_10_10\n",
      "\n",
      "Input:  9_8_6_4\n",
      "Output: 8_8_6_4_4_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10\n",
      "\n",
      "Input:  17_22_12_7_4_19_9_20_9_8_21_6_21\n",
      "Output: 17_22_12_21_4_19_20_9_9_8_21_21_21_21_21_21_21_21_21_10_10_10_10_10_10\n",
      "\n",
      "Input:  3_5_22_12_21\n",
      "Output: 5_13_15_12_21_21_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "        \n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            encoder_embedding,\n",
    "            max_length=25,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "        \n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"_\".join(input_symbols))\n",
    "            print(\"Output:\", \"_\".join(output_symbols))\n",
    "            print()\n",
    "            \n",
    "            if i_input == 10:\n",
    "                break\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances for evaluation\n",
    "n_eval_utterances = len(prepared_text)  # 1000  # 10000  # 1000\n",
    "# eval_sentences = prepared_text[-n_eval_utterances:]  # val sentences\n",
    "# eval_utterances = list(utterances)[-n_eval_utterances:]\n",
    "eval_sentences = prepared_text[:n_eval_utterances]\n",
    "eval_utterances = list(utterances)[:n_eval_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167767/167767 [13:57<00:00, 200.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = eval_sentences\n",
    "# sentences = cur_val_sentences\n",
    "interval_dataset = datasets.SentenceIntervalDataset(\n",
    "    sentences,\n",
    "    text_to_id,\n",
    "    join_char=\"_\"\n",
    "    )\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "eos = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss.cpu().numpy())\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16355/16355 [00:10<00:00, 1526.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL: -3610045.1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Segment\n",
    "\n",
    "dur_weight = 10.0\n",
    "\n",
    "i_item = 0\n",
    "losses = []\n",
    "cur_segmented_sentences = []\n",
    "for i_sentence, intervals in enumerate(tqdm(interval_dataset.intervals)):\n",
    "    \n",
    "    # Costs for segment intervals\n",
    "    costs = np.inf*np.ones(len(intervals))\n",
    "    i_eos = intervals[-1][-1]\n",
    "    for i_seg, interval in enumerate(intervals):\n",
    "        if interval is None:\n",
    "            continue\n",
    "        i_start, i_end = interval\n",
    "        dur = i_end - i_start\n",
    "        assert dur == lengths[i_item]\n",
    "        eos = (i_end == i_eos)  # end-of-sequence\n",
    "        \n",
    "        # Chorowski\n",
    "        costs[i_seg] = (\n",
    "            rnn_losses[i_item]\n",
    "            + dur_weight*neg_chorowski(dur)\n",
    "            )\n",
    "        \n",
    "#         # Gamma\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*neg_log_gamma(dur)\n",
    "#             + np.log(np.sum(gamma_cache**dur_weight))\n",
    "#             )\n",
    "        \n",
    "#         # Poisson\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + neg_log_poisson(dur)\n",
    "#             )\n",
    "\n",
    "#         # Histogram\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*(neg_log_hist(dur))\n",
    "#             + np.log(np.sum(histogram**dur_weight))\n",
    "#             )\n",
    "    \n",
    "#         # Sequence boundary\n",
    "#         alpha = 0.3  # 0.3  # 0.9\n",
    "#         if eos:\n",
    "#             costs[i_seg] += -np.log(alpha)\n",
    "#         else:\n",
    "#             costs[i_seg] += -np.log(1 - alpha)\n",
    "# #             K = 5000\n",
    "# #             costs[i_seg] += -np.log((1 - alpha)/K)\n",
    "\n",
    "        # Temp\n",
    "#         if dur > 10 or dur <= 1:\n",
    "#             costs[i_seg] = +np.inf\n",
    "        i_item += 1\n",
    "    \n",
    "    # Viterbi segmentation\n",
    "    n_frames = len(interval_dataset.sentences[i_sentence])\n",
    "    summed_cost, boundaries = viterbi.custom_viterbi(costs, n_frames)\n",
    "    losses.append(summed_cost)\n",
    "    \n",
    "    reference_sentence = sentences[i_sentence]\n",
    "    segmented_sentence = get_segmented_sentence(\n",
    "            interval_dataset.sentences[i_sentence],\n",
    "            boundaries\n",
    "            )\n",
    "    cur_segmented_sentences.append(segmented_sentence)\n",
    "#     # Print examples of the first few sentences\n",
    "#     if i_sentence < 10:\n",
    "#         print(reference_sentence)\n",
    "#         print(segmented_sentence)\n",
    "#         print()\n",
    "    \n",
    "print(\"NLL: {:.4f}\".format(np.sum(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23_6_15_4_19_20_9_0_23_8_2 8_21_11_16_4_7_19_9_2_8_6_7\n"
     ]
    }
   ],
   "source": [
    "print(cur_segmented_sentences[0])\n",
    "\n",
    "# # To evaluate gold segmentation:\n",
    "# cur_segmented_sentences = prepared_text_gold[:n_eval_utterances]\n",
    "# print(cur_segmented_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16355it [00:00, 90225.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 24, '23_6_15_4_19_20_9_0_23_8_2'), (24, 64, '8_21_11_16_4_7_19_9_2_8_6_7')]\n",
      "[(0, 19, 'those'), (19, 55, 'parents'), (55, 64, 'were')]\n",
      "\n",
      "[(0, 29, '12_14_24_18_1_10_17_22_15_12_2')]\n",
      "[(0, 11, 'i'), (11, 29, 'went')]\n",
      "\n",
      "[(0, 28, '5_15_3_13_22_15_2_4_3'), (28, 33, '1_13_14_5_22'), (33, 56, '1_17_22_15_12_4_5_3_1_13'), (56, 100, '17_22_15_2_21_4_5_0_20_5_21_17_11')]\n",
      "[(0, 20, 'no'), (20, 33, 'in'), (33, 57, 'one'), (57, 99, 'week')]\n",
      "\n",
      "[(0, 33, '23_17_22_15_2_11_3_7_4_7_0'), (33, 50, '8_5_6_7_22_0_5_15_6_2_4')]\n",
      "[(0, 9, 'when'), (9, 15, 'it'), (15, 42, 'happened'), (42, 49, 'in')]\n",
      "\n",
      "[(0, 24, '23_6_7_19_8_22_1_7_19_9'), (24, 65, '8_2_6_3_7_19_9_8_1_7_19_9_0_8_9'), (65, 103, '3_10_5_20_8_17_22_15_2_7_16_9_8_1_7')]\n",
      "[(0, 10, 'it'), (10, 25, 'was'), (25, 59, 'useless'), (59, 69, 'to'), (69, 95, 'fight'), (95, 103, 'it')]\n",
      "\n",
      "[(0, 15, '23_6_4_3_5_17'), (15, 31, '6_15_18_12_7_5_0_24'), (31, 72, '19_9_8_6_3_7_19_9')]\n",
      "[(0, 15, 'and'), (15, 31, 'not'), (31, 71, 'just')]\n",
      "\n",
      "[(0, 23, '23_24_6_11_18_12_19_9_10'), (23, 53, '0_24_8_6_2_4_7_4_10_0_24_21_1_21_2'), (53, 85, '11_3_13_14_17_22_15_4_19_0_24_9_3'), (85, 123, '24_18_24_1_18_15_12_19_20_9_20_0_24_9_10')]\n",
      "[(0, 24, 'tough'), (24, 37, 'to'), (37, 52, 'be'), (52, 67, 'able'), (67, 74, 'to'), (74, 123, 'trust')]\n",
      "\n",
      "[(0, 41, '0_19_9_8_1_13_18_12_10_5_10')]\n",
      "[(0, 40, 'son')]\n",
      "\n",
      "[(0, 21, '16_14_16_2_14_16_14_21_16'), (21, 34, '0_16_2_4_5_0_11'), (34, 75, '24_8_11_12_10_4_0_22_24_21_0_21_4_0'), (75, 99, '24_9_8_6_2_4_5_21_23_14'), (99, 126, '0_19_20_8_21_5_0_21_11'), (126, 142, '18_15_12_21_4_3_4_3_10')]\n",
      "[(0, 12, 'gonna'), (12, 24, 'get'), (24, 28, 'a'), (28, 57, 'puppy'), (57, 66, 'and'), (66, 70, 'a'), (70, 100, 'kitten'), (100, 141, 'together')]\n",
      "\n",
      "[(0, 35, '5_19_5_20_8_6_2_11_18_12_4_10')]\n",
      "[(0, 35, 'yet')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert segmentation to intervals\n",
    "segmentation_interval_dict = {}\n",
    "for i_utt, utt_key in tqdm(enumerate(eval_utterances)):\n",
    "    words_segmented = cur_segmented_sentences[i_utt].split(\" \")\n",
    "    word_start = 0\n",
    "    word_label = \"\"\n",
    "    i_word = 0\n",
    "    segmentation_interval_dict[utt_key] = []\n",
    "    for (phone_start, phone_end,\n",
    "            phone_label) in phoneseg_interval_dict[utt_key]:\n",
    "        word_label += phone_label + \"_\"\n",
    "        if words_segmented[i_word] == word_label[:-1]:\n",
    "            segmentation_interval_dict[utt_key].append((\n",
    "                word_start, phone_end, word_label[:-1]\n",
    "                ))\n",
    "            word_label = \"\"\n",
    "            word_start = phone_end\n",
    "            i_word += 1\n",
    "\n",
    "    if i_utt < 10:\n",
    "        print(segmentation_interval_dict[utt_key])\n",
    "        print(word_ref_interval_dict[utt_key])\n",
    "        print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16355/16355 [00:00<00:00, 316442.82it/s]\n",
      "100%|██████████| 16355/16355 [00:00<00:00, 325066.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Word boundaries:\n",
      "Precision: 28.45%\n",
      "Recall: 17.64%\n",
      "F-score: 21.78%\n",
      "OS: -37.99%\n",
      "R-value: 38.96%\n",
      "---------------------------------------------------------------------------\n",
      "Word token boundaries:\n",
      "Precision: 18.58%\n",
      "Recall: 15.13%\n",
      "F-score: 16.68%\n",
      "OS: -18.59%\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Intervals to boundaries\n",
    "segmentation_boundaries_dict = {}\n",
    "for utt_key in tqdm(segmentation_interval_dict):\n",
    "    segmentation_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        segmentation_interval_dict[utt_key]\n",
    "        )\n",
    "word_ref_boundaries_dict = {}\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    word_ref_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        word_ref_interval_dict[utt_key]\n",
    "        )\n",
    "\n",
    "# Evaluate word boundaries\n",
    "reference_list = []\n",
    "segmentation_list = []\n",
    "for utterance in segmentation_boundaries_dict:\n",
    "    reference_list.append(word_ref_boundaries_dict[utterance])\n",
    "    segmentation_list.append(segmentation_boundaries_dict[utterance])\n",
    "\n",
    "tolerance = 2\n",
    "p, r, f = eval_segmentation.score_boundaries(\n",
    "    reference_list, segmentation_list, tolerance=tolerance\n",
    "    )\n",
    "print(\"-\"*(79 - 4))\n",
    "print(\"Word boundaries:\")\n",
    "print(\"Precision: {:.2f}%\".format(p*100))\n",
    "print(\"Recall: {:.2f}%\".format(r*100))\n",
    "print(\"F-score: {:.2f}%\".format(f*100))\n",
    "print(\"OS: {:.2f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "print(\"R-value: {:.2f}%\".format(eval_segmentation.get_rvalue(p, r)*100))\n",
    "print(\"-\"*(79 - 4))\n",
    "\n",
    "p, r, f = eval_segmentation.score_word_token_boundaries(\n",
    "    reference_list, segmentation_list, tolerance=tolerance\n",
    "    )\n",
    "print(\"Word token boundaries:\")\n",
    "print(\"Precision: {:.2f}%\".format(p*100))\n",
    "print(\"Recall: {:.2f}%\".format(r*100))\n",
    "print(\"F-score: {:.2f}%\".format(f*100))\n",
    "print(\"OS: {:.2f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "# print(\"R-value: {:.2f}%\".format(get_rvalue(p, r)*100))\n",
    "print(\"-\"*(79 - 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1097/16355 [00:00<00:01, 10967.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to: ../../vqwordseg/exp/gmm/buckeye/val/wordseg_segaernn_dp_penalized_25/intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16355/16355 [00:02<00:00, 7873.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Write intervals to a directory\n",
    "output_tag = \"wordseg_segaernn_{}\".format(seg_tag.replace(\"phoneseg_\", \"\"))\n",
    "output_dir = (\n",
    "    Path(\"../../vqwordseg/exp\")/vq_model/dataset/split/output_tag/\"intervals\"\n",
    "    )\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"Writing to: {output_dir}\")\n",
    "for utt_key in tqdm(segmentation_interval_dict):\n",
    "    with open((output_dir/utt_key).with_suffix(\".txt\"), \"w\") as f:\n",
    "        for (i_segment, (start, end, label)) in enumerate(segmentation_interval_dict[utt_key]):\n",
    "#             label = cluster_dict[utt_key][i_segment]\n",
    "            f.write(f\"{start:d} {end:d} {label}_\\n\")\n",
    "            \n",
    "#         for start, end, label in segmentation_interval_dict[utt_key]:\n",
    "# #             f.write(f\"{start:d} {end:d} {label}\\n\")\n",
    "#             f.write(f\"{start:d} {end:d} {label}_\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering_sentences = prepared_text_gold[:10000]\n",
    "# clustering_sentences = prepared_text[:10000]  # probably doesn't make sense\n",
    "clustering_sentences = cur_segmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1636/1636 [00:05<00:00, 303.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (52342, 50)\n",
      "2021-10-26 14:29:33.685462\n",
      "Clustering: K = 8192\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c76633ea3777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Clustering: K = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mkmeans_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mkmeans_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inertia: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0;31m# run a k-means once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             labels, inertia, centers, n_iter_ = kmeans_single(\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, sample_weight, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, n_threads)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     centers = _init_centroids(X, n_clusters, init, random_state=random_state,\n\u001b[0m\u001b[1;32m    406\u001b[0m                               x_squared_norms=x_squared_norms)\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_init_centroids\u001b[0;34m(X, n_clusters, init, random_state, x_squared_norms, init_size)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         centers = _k_init(X, n_clusters, random_state=random_state,\n\u001b[0m\u001b[1;32m    722\u001b[0m                           x_squared_norms=x_squared_norms)\n\u001b[1;32m    723\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_k_init\u001b[0;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# Compute distances to center candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         distance_to_candidates = euclidean_distances(\n\u001b[0m\u001b[1;32m    121\u001b[0m             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# To minimize precision issues with float32, we compute the distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# matrix on chunks of X and Y upcast to float64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_euclidean_distances_upcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances_upcast\u001b[0;34m(X, XX, Y, YY, batch_size)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0mYY_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K-means centroids\n",
    "\n",
    "# Data\n",
    "train_dataset = datasets.WordDataset(\n",
    "    clustering_sentences, text_to_id, n_symbols_max=n_symbols_max\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.eval()\n",
    "encoder_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "        encoder_embeddings.append(encoder_embedding.cpu().numpy())\n",
    "        \n",
    "# Cluster\n",
    "X = np.vstack(encoder_embeddings)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(datetime.now())\n",
    "K = 8192  # 4096  # 1024 # 4096 # 1024  # 2048\n",
    "print(\"Clustering: K = {}\".format(K))\n",
    "kmeans_model = cluster.KMeans(n_clusters=K, max_iter=10)\n",
    "kmeans_model.fit(X)\n",
    "print(\"Inertia: {:.4f}\".format(kmeans_model.inertia_))\n",
    "centroids = kmeans_model.cluster_centers_\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster labels for current segmentation\n",
    "clusters = kmeans_model.predict(X)\n",
    "cluster_dict = {}\n",
    "i_embedding = 0\n",
    "for i_utt, utt_key in tqdm(enumerate(eval_utterances)):\n",
    "#     print(clustering_sentences[i_utt].split(\" \"))\n",
    "    n_embeddings = len(clustering_sentences[i_utt].split(\" \"))\n",
    "    cur_clusters = []\n",
    "    for i_cur_embedding in range(n_embeddings):\n",
    "        cur_clusters.append(clusters[i_embedding + i_cur_embedding])\n",
    "#         print(i_embedding + i_cur_embedding, clusters[i_embedding + i_cur_embedding])\n",
    "#     print(\".\")\n",
    "    cluster_dict[utt_key] = cur_clusters\n",
    "    i_embedding += n_embeddings\n",
    "#     if i_embedding == 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write intervals to a directory\n",
    "output_tag = \"wordseg_segaernn_kmeans_{}\".format(seg_tag.replace(\"phoneseg_\", \"\"))\n",
    "output_dir = (\n",
    "    Path(\"../../vqwordseg/exp\")/vq_model/dataset/split/output_tag/\"intervals\"\n",
    "    )\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"Writing to: {output_dir}\")\n",
    "for utt_key in tqdm(segmentation_interval_dict):\n",
    "    with open((output_dir/utt_key).with_suffix(\".txt\"), \"w\") as f:\n",
    "        for (i_segment, (start, end, label)) in enumerate(segmentation_interval_dict[utt_key]):\n",
    "            label = cluster_dict[utt_key][i_segment]\n",
    "            f.write(f\"{start:d} {end:d} {label}_\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "#     for i_batch, (data, data_lengths) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        encoder_embedding = encoder_embedding.cpu().numpy()\n",
    "        clusters = kmeans_model.predict(encoder_embedding)\n",
    "        embedding_reconstructed = centroids[clusters, :].reshape(\n",
    "            encoder_embedding.shape\n",
    "            )\n",
    "        embedding_reconstructed = torch.from_numpy(\n",
    "            embedding_reconstructed\n",
    "            ).to(device)\n",
    "        \n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            embedding_reconstructed,\n",
    "            max_length=n_symbols_max,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "        \n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"_\".join(input_symbols))\n",
    "            print(\"Output:\", \"_\".join(output_symbols))\n",
    "            print()\n",
    "            \n",
    "            if i_input == 10:\n",
    "                break\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances for evaluation\n",
    "n_eval_utterances = len(prepared_text)  # 1000  # 10000  # 1000\n",
    "# eval_sentences = prepared_text[-n_eval_utterances:]  # val sentences\n",
    "# eval_utterances = list(utterances)[-n_eval_utterances:]\n",
    "eval_sentences = prepared_text[:n_eval_utterances]\n",
    "eval_utterances = list(utterances)[:n_eval_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = eval_sentences\n",
    "interval_dataset = datasets.SentenceIntervalDataset(\n",
    "    sentences,\n",
    "    text_to_id,\n",
    "    \"_\"\n",
    "    )\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0  # to-do: adjust this\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        encoder_embedding = encoder_embedding.cpu().numpy()\n",
    "        clusters = kmeans_model.predict(encoder_embedding)\n",
    "        embedding_reconstructed = centroids[clusters, :].reshape(\n",
    "            encoder_embedding.shape\n",
    "            )\n",
    "        embedding_reconstructed = torch.from_numpy(\n",
    "            embedding_reconstructed\n",
    "            ).to(device)\n",
    "        \n",
    "        decoder_rnn, decoder_output = model.decoder(\n",
    "            embedding_reconstructed, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss)\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options:\n",
    "\n",
    "- Want to evaluate this segmentation: Go back up to the cell where segmentation is done (after segments are embedded).\n",
    "- Want to retrain K-means model based on this segmentation: Go back to start of the quantization cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
