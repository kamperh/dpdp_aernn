{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation on ZeroSpeech'17 Mandarin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2021 Herman Kamper, MIT License\n",
    "\n",
    "Train a segmental autoencoding recurrent neural network (segmental AE-RNN) and perform word segmentation on encoded ZeroSpeech'17 Mandarin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy.stats import gamma\n",
    "from sklearn import cluster\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from seg_aernn import datasets, models, viterbi\n",
    "from utils import eval_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented_sentence(ids, boundaries):\n",
    "    output = \"\"\n",
    "    cur_word = []\n",
    "    for i_symbol, boundary in enumerate(boundaries):\n",
    "        cur_word.append(id_to_symbol[ids[i_symbol]])\n",
    "        if boundary:\n",
    "            output += \"_\".join(cur_word)\n",
    "            output += \" \"\n",
    "            cur_word = []\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration penalty functions\n",
    "\n",
    "\"\"\"\n",
    "# Histogram\n",
    "histogram = np.array([\n",
    "    0, 1.66322800e-01, 2.35838129e-01, 2.10609187e-01,\n",
    "    1.48025482e-01, 9.42918160e-02, 5.84211098e-02, 3.64679480e-02,\n",
    "    2.18264741e-02, 1.25420784e-02, 7.18500018e-03, 4.27118399e-03,\n",
    "    1.73743077e-03, 1.19448366e-03, 7.42027726e-04, 2.89571796e-04,\n",
    "    2.35277084e-04, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001\n",
    "    ])  # to-do: check this\n",
    "histogram = histogram/np.sum(histogram)\n",
    "def neg_log_hist(dur):\n",
    "    return -np.log(0 if dur >= len(histogram) else histogram[dur])\n",
    "\n",
    "# Cached Gamma\n",
    "# shape, loc, scale = (2.3, 0, 1.3)  # VQ-VAE\n",
    "shape, loc, scale = (2.6, 0, 1.8)    # CPC-big\n",
    "# shape, loc, scale = (2.5, 0, 1.5)    # CPC-big (Gamma)\n",
    "gamma_cache = []\n",
    "for dur in range(200):\n",
    "    gamma_cache.append(gamma.pdf(dur, shape, loc, scale))\n",
    "gamma_cache = np.array(gamma_cache)/np.sum(gamma_cache)\n",
    "def neg_log_gamma(dur):\n",
    "    if dur < 200:\n",
    "        return -np.log(gamma_cache[dur])\n",
    "    else:\n",
    "        return -np.log(0)\n",
    "\"\"\"\n",
    "    \n",
    "# Chorowski\n",
    "def neg_chorowski(dur):\n",
    "    return -(dur - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "vq_model = \"cpc_big\"\n",
    "# vq_model = \"xlsr\"\n",
    "# dataset = \"zs2017_zh\"\n",
    "dataset = \"zs2017_zh\"\n",
    "split = \"train\"\n",
    "seg_tag = \"phoneseg_dp_penalized\"\n",
    "# seg_tag = \"phoneseg_dp_penalized_tune\"\n",
    "\n",
    "# Paths\n",
    "seg_dir = (\n",
    "    Path(\"../../vqwordseg/exp\")/vq_model/dataset/split/seg_tag/\"intervals\"\n",
    "    )\n",
    "# word_ref_dir = Path(\"../../vqwordseg/data\")/dataset/\"word_intervals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1689/5285 [00:00<00:00, 16884.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../../vqwordseg/exp/cpc_big/zs2017_zhtmp/train/phoneseg_dp_penalized/intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5285/5285 [00:00<00:00, 16734.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read phone segmentation\n",
    "phoneseg_interval_dict = {}\n",
    "print(\"Reading: {}\".format(seg_dir))\n",
    "phoneseg_interval_dict = eval_segmentation.get_intervals_from_dir(seg_dir)\n",
    "utterances = phoneseg_interval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5285/5285 [00:00<00:00, 501218.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_37_12_18_39_8_28_18_24_1_18_20_49_36_24_1_31_45_2_13_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepared_text = []\n",
    "for utt_key in tqdm(utterances):\n",
    "    prepared_text.append(\n",
    "        \"_\".join([i[2] for i in phoneseg_interval_dict[utt_key]])\n",
    "        )\n",
    "print(prepared_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 35, 8, 14, 37, 52, 25, 14, 21, 5, 14, 17, 48, 34, 21, 5, 29, 44, 16, 9, 27]\n",
      "['4', '37', '12', '18', '39', '8', '28', '18', '24', '1', '18', '20', '49', '36', '24', '1', '31', '45', '2', '13', '3']\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary\n",
    "PAD_SYMBOL      = \"<pad>\"\n",
    "SOS_SYMBOL      = \"<s>\"    # start of sentence\n",
    "EOS_SYMBOL      = \"</s>\"   # end of sentence\n",
    "BOUNDARY_SYMBOL = \" \"      # word boundary\n",
    "symbols = set()\n",
    "for sentence in prepared_text:\n",
    "    for char in sentence.split(\"_\"):\n",
    "        symbols.add(char)\n",
    "SYMBOLS = [PAD_SYMBOL, SOS_SYMBOL, EOS_SYMBOL, BOUNDARY_SYMBOL] + (sorted(list(symbols)))\n",
    "symbol_to_id = {s: i for i, s in enumerate(SYMBOLS)}\n",
    "id_to_symbol = {i: s for i, s in enumerate(SYMBOLS)}\n",
    "\n",
    "def text_to_id(text, add_sos_eos=False):\n",
    "    \"\"\"\n",
    "    Convert text to a list of symbol IDs.\n",
    "\n",
    "    Sentence start and end symbols can be added by setting `add_sos_eos`.\n",
    "    \"\"\"\n",
    "    symbol_ids = []\n",
    "    for word in text.split(\" \"):\n",
    "        for code in word.split(\"_\"):\n",
    "            symbol_ids.append(symbol_to_id[code])\n",
    "        symbol_ids.append(symbol_to_id[BOUNDARY_SYMBOL])\n",
    "    symbol_ids = symbol_ids[:-1]  # remove last space\n",
    "\n",
    "    if add_sos_eos:\n",
    "        return [symbol_to_id[SOS_SYMBOL]] + symbol_ids + [symbol_to_id[EOS_SYMBOL]]\n",
    "    else:\n",
    "        return symbol_ids\n",
    "\n",
    "print(text_to_id(prepared_text[0]))\n",
    "print([id_to_symbol[i] for i in text_to_id(prepared_text[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_37_12_18_39_8_28_18_24_1_18_20_49_36_24_1_31_45_2_13_3\n",
      "4_25_12_27_31_3_47_1_15_20_22\n",
      "4_37_38_23_7_11_46_38_18_5_43_40_14_36_9_43_40_11\n",
      "8_48_18_20_8_41_18_20_29\n",
      "4_0_32_41_47_1_18_34_44_0_28_23_11_14_34_44_0_41_1_19_31_3_16_0_28_18_47_1_21_8_48_27_29\n",
      "4_9_47_18_42_1_48_27_20_29_49_43_7_14_39_32_28_18_47_1_18_29_16\n",
      "4_25_10_37_48_27_5_24_1_19_33_45_25_12_27_31_3_16_44_37_41_18_21_46_44_37_25_40_7_10\n"
     ]
    }
   ],
   "source": [
    "# First three words of training data\n",
    "word_dataset = datasets.WordDataset(prepared_text, text_to_id)\n",
    "for i in range(7):\n",
    "    sample = word_dataset[i]\n",
    "    print(\"_\".join([id_to_symbol[i] for i in sample.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. train sentences: 5285\n",
      "Examples: ['4_37_12_18_39_8_28_18_24_1_18_20_49_36_24_1_31_45_2_13_3', '4_25_12_27_31_3_47_1_15_20_22', '4_37_38_23_7_11_46_38_18_5_43_40_14_36_9_43_40_11']\n",
      "Min length:  1\n",
      "Max length:  170\n",
      "Mean length: 29.0956\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "cur_val_sentences = prepared_text[-100:]\n",
    "cur_train_sentences = prepared_text\n",
    "\n",
    "# Random boundaries\n",
    "np.random.seed(42)\n",
    "# cur_train_sentences = insert_random_boundaries(cur_train_sentences)\n",
    "# cur_val_sentences = insert_random_boundaries(cur_val_sentences)\n",
    "\n",
    "print(\"No. train sentences:\", len(cur_train_sentences))\n",
    "print(\"Examples:\", cur_train_sentences[:3])\n",
    "print(\"Min length: \", min([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Max length: \", max([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Mean length: {:.4f}\".format(np.mean([len(i.split(\"_\")) for i in cur_train_sentences])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE-RNN model\n",
    "n_symbols = len(SYMBOLS)\n",
    "symbol_embedding_dim = 10  # 25\n",
    "hidden_dim = 500  # 250  # 500  # 1000  # 200\n",
    "embedding_dim = 50  # 150  # 300  # 25\n",
    "teacher_forcing_ratio = 0.5  # 1.0  # 0.5  # 1.0\n",
    "n_encoder_layers = 1  # 1  # 3  # 10\n",
    "n_decoder_layers = 1  # 1  # 1\n",
    "batch_size = 32  # 32*3  # 32\n",
    "learning_rate = 0.001\n",
    "input_dropout = 0.0  # 0.0 # 0.5\n",
    "dropout = 0.0\n",
    "n_symbols_max = 50  # 25\n",
    "# n_epochs_max = 5\n",
    "n_epochs_max = None  # determined from n_max_steps and batch size\n",
    "n_steps_max = 1500  # 2500  # 1500  # 1000  # None\n",
    "# n_steps_max = None  # Only use n_epochs_max\n",
    "bidirectional_encoder = False  # False\n",
    "\n",
    "encoder = models.Encoder(\n",
    "    n_symbols=n_symbols,\n",
    "    symbol_embedding_dim=symbol_embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_encoder_layers,\n",
    "    dropout=dropout,\n",
    "    input_dropout=input_dropout,\n",
    "    bidirectional=bidirectional_encoder\n",
    "    )\n",
    "# decoder = models.Decoder1(\n",
    "#     n_symbols=n_symbols,\n",
    "#     symbol_embedding_dim=symbol_embedding_dim,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     n_layers=n_decoder_layers,\n",
    "#     sos_id = symbol_to_id[SOS_SYMBOL],\n",
    "#     teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "#     dropout=dropout\n",
    "#     )\n",
    "decoder = models.Decoder2(\n",
    "    n_symbols=n_symbols,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_decoder_layers,\n",
    "    dropout=dropout\n",
    "    )\n",
    "model = models.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:04<00:00, 33.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 100.139, val loss: 94.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:05<00:00, 32.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 93.460, val loss: 101.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:05<00:00, 32.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 90.882, val loss: 92.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 166/166 [00:05<00:00, 32.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 88.192, val loss: 85.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 166/166 [00:04<00:00, 33.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss: 85.429, val loss: 86.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:04<00:00, 33.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss: 81.994, val loss: 83.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:04<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, train loss: 78.668, val loss: 78.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:04<00:00, 33.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, train loss: 75.795, val loss: 71.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:04<00:00, 33.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train loss: 72.489, val loss: 76.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/166 [00:00<00:05, 28.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, train loss: 77.842, val loss: 60.722\n"
     ]
    }
   ],
   "source": [
    "# Training device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Training data\n",
    "train_dataset = datasets.WordDataset(\n",
    "    cur_train_sentences, text_to_id, n_symbols_max=n_symbols_max\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Validation data\n",
    "val_dataset = datasets.WordDataset(cur_val_sentences, text_to_id)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Loss\n",
    "criterion = nn.NLLLoss(\n",
    "    reduction=\"sum\", ignore_index=symbol_to_id[PAD_SYMBOL]\n",
    "    )\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "if n_epochs_max is None:\n",
    "    steps_per_epoch = np.ceil(len(cur_train_sentences)/batch_size)\n",
    "    n_epochs_max = int(np.ceil(n_steps_max/steps_per_epoch))\n",
    "\n",
    "i_step = 0\n",
    "for i_epoch in range(n_epochs_max):\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        optimiser.zero_grad()\n",
    "        data = data.to(device)       \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_output.contiguous().view(-1, decoder_output.size(-1)),\n",
    "            data.contiguous().view(-1)\n",
    "            )\n",
    "        loss /= len(data_lengths)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        train_losses.append(loss.item())\n",
    "        i_step += 1\n",
    "        if i_step == n_steps_max and n_steps_max is not None:\n",
    "            break\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "            data = data.to(device)            \n",
    "            encoder_embedding, decoder_output = model(\n",
    "                data, data_lengths, data, data_lengths\n",
    "                )\n",
    "\n",
    "            loss = criterion(\n",
    "                decoder_output.contiguous().view(-1,\n",
    "                decoder_output.size(-1)), data.contiguous().view(-1)\n",
    "                )\n",
    "            loss /= len(data_lengths)\n",
    "            val_losses.append(loss.item())\n",
    "    \n",
    "    print(\n",
    "        \"Epoch {}, train loss: {:.3f}, val loss: {:.3f}\".format(\n",
    "        i_epoch,\n",
    "        np.mean(train_losses),\n",
    "        np.mean(val_losses))\n",
    "        )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if i_step == n_steps_max and n_steps_max is not None:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  4_25_12_40_12_33_31_22_38_26_39_32_35_28_36_17_22_16_0_35_41_17_39_32_35_41_17_29_4\n",
      "Output: 4_25_12_40_12_26_26_26_39_39_39_35_35_35_35_35_35_17_17_17_17_17_17_17_17\n",
      "\n",
      "Input:  4_9_1_15_20_49_23_40_14_34_38_23_12_14_39_32_28_19_31_5_1_21_39_35_6_1_15_29\n",
      "Output: 4_9_1_15_20_49_23_40_14_39_23_23_14_14_39_39_28_39_39_35_35_35_15_15_15\n",
      "\n",
      "Input:  4_9_43_11_3_24_1_43_33_13_10\n",
      "Output: 4_9_43_14_36_9_1_1_43_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10_10\n",
      "\n",
      "Input:  24_1_21_0_43_40_12_26_20_22_16_37_41_24_1_21_49_38_13_4\n",
      "Output: 4_9_1_43_45_12_26_22_16_16_16_16_16_21_21_38_33_13_13_13_4_4_4_4_4\n",
      "\n",
      "Input:  4_0_28_23_33_31_3_16_37_25_12_26_20_22\n",
      "Output: 4_0_28_19_31_31_16_37_37_12_12_20_22_16_16_16_16_16_16_16_37_37_12_12_12\n",
      "\n",
      "Input:  4_32_35_28_19_33_39_8_38_34_37_2_33_10_8_38_26_5_39_41_15_20_22_16_44_0_28_23_40_14_36_34_38_20_39_32_28_42_36_34_41_1_15_20_34_44_35_30_15_21_44_37_25_40_10_45_25_33_31_22_16_38_26_29\n",
      "Output: 4_0_35_28_19_31_3_8_38_38_26_34_38_0_38_38_26_38_44_44_44_44_34_44_44\n",
      "\n",
      "Input:  4_37_23_11_22_16_37_38_2_31_46_38_26_43_25_12_5_20_22_16_0_35_30_23_11_3_36_39_32_28_6_36_17_9_1_15_29\n",
      "Output: 4_37_23_31_3_16_37_30_2_20_22_16_16_23_23_22_16_16_23_23_36_36_36_36_36\n",
      "\n",
      "Input:  4_0_28_23_31_11_46_16_8_38_19_33_14_49_42_25_12_5_15_39_8_38_19_33_14_34_0_38_19_33_20_22_38_26_31_10_44_37_25_12_14_46_36_20_22_49_38_19_33_31_11_25_12_26_5_22_16_0_6_15_20_22_16_37_30_2_20_22_38_20_39_35_41_15_20_22_16\n",
      "Output: 4_0_28_23_40_14_49_38_38_19_31_38_38_38_38_38_38_38_38_38_38_38_38_38_38\n",
      "\n",
      "Input:  4_25_12_14_34_0_28_18_49_39_32_28_6_43_25_14_39_8_28_23_40_13\n",
      "Output: 4_25_12_14_39_0_41_18_39_39_32_28_23_23_39_39_32_28_40_40_13_13_13_13_13\n",
      "\n",
      "Input:  0_28_23_11_3_16_8_35_41_24_6_29\n",
      "Output: 4_8_23_11_3_16_35_41_6_21_29_29_29_29_6_6_6_41_41_6_21_29_29_29_29\n",
      "\n",
      "Input:  4\n",
      "Output: 4_49_40_11_3_16_38_20_16_16_16_16_16_16_4_4_4_16_16_16_16_16_16_16_16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "        \n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            encoder_embedding,\n",
    "            max_length=25,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "        \n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"_\".join(input_symbols))\n",
    "            print(\"Output:\", \"_\".join(output_symbols))\n",
    "            print()\n",
    "            \n",
    "            if i_input == 10:\n",
    "                break\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances for evaluation\n",
    "n_eval_utterances = len(prepared_text)  # 1000  # 10000  # 1000\n",
    "# eval_sentences = prepared_text[-n_eval_utterances:]  # val sentences\n",
    "# eval_utterances = list(utterances)[-n_eval_utterances:]\n",
    "eval_sentences = prepared_text[:n_eval_utterances]\n",
    "eval_utterances = list(utterances)[:n_eval_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55684/55684 [04:31<00:00, 205.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = eval_sentences\n",
    "# sentences = cur_val_sentences\n",
    "interval_dataset = datasets.SentenceIntervalDataset(\n",
    "    sentences,\n",
    "    text_to_id,\n",
    "    join_char=\"_\"\n",
    "    )\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "eos = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss.cpu().numpy())\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5285/5285 [00:03<00:00, 1450.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL: -180370.4314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Segment\n",
    "\n",
    "dur_weight = 3.0\n",
    "\n",
    "i_item = 0\n",
    "losses = []\n",
    "cur_segmented_sentences = []\n",
    "for i_sentence, intervals in enumerate(tqdm(interval_dataset.intervals)):\n",
    "    \n",
    "    # Costs for segment intervals\n",
    "    costs = np.inf*np.ones(len(intervals))\n",
    "    i_eos = intervals[-1][-1]\n",
    "    for i_seg, interval in enumerate(intervals):\n",
    "        if interval is None:\n",
    "            continue\n",
    "        i_start, i_end = interval\n",
    "        dur = i_end - i_start\n",
    "        assert dur == lengths[i_item]\n",
    "        eos = (i_end == i_eos)  # end-of-sequence\n",
    "        \n",
    "        # Chorowski\n",
    "        costs[i_seg] = (\n",
    "            rnn_losses[i_item]\n",
    "            + dur_weight*neg_chorowski(dur)\n",
    "            )\n",
    "        \n",
    "#         # Gamma\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*neg_log_gamma(dur)\n",
    "#             + np.log(np.sum(gamma_cache**dur_weight))\n",
    "#             )\n",
    "        \n",
    "#         # Poisson\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + neg_log_poisson(dur)\n",
    "#             )\n",
    "\n",
    "#         # Histogram\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*(neg_log_hist(dur))\n",
    "#             + np.log(np.sum(histogram**dur_weight))\n",
    "#             )\n",
    "    \n",
    "#         # Sequence boundary\n",
    "#         alpha = 0.3  # 0.3  # 0.9\n",
    "#         if eos:\n",
    "#             costs[i_seg] += -np.log(alpha)\n",
    "#         else:\n",
    "#             costs[i_seg] += -np.log(1 - alpha)\n",
    "# #             K = 5000\n",
    "# #             costs[i_seg] += -np.log((1 - alpha)/K)\n",
    "\n",
    "        # Temp\n",
    "#         if dur > 10 or dur <= 1:\n",
    "#             costs[i_seg] = +np.inf\n",
    "        i_item += 1\n",
    "    \n",
    "    # Viterbi segmentation\n",
    "    n_frames = len(interval_dataset.sentences[i_sentence])\n",
    "    summed_cost, boundaries = viterbi.custom_viterbi(costs, n_frames)\n",
    "    losses.append(summed_cost)\n",
    "    \n",
    "    reference_sentence = sentences[i_sentence]\n",
    "    segmented_sentence = get_segmented_sentence(\n",
    "            interval_dataset.sentences[i_sentence],\n",
    "            boundaries\n",
    "            )\n",
    "    cur_segmented_sentences.append(segmented_sentence)\n",
    "#     # Print examples of the first few sentences\n",
    "#     if i_sentence < 10:\n",
    "#         print(reference_sentence)\n",
    "#         print(segmented_sentence)\n",
    "#         print()\n",
    "    \n",
    "print(\"NLL: {:.4f}\".format(np.sum(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_37_12_18_39_8_28_18_24_1_18_20 49_36_24_1_31_45_2_13_3\n"
     ]
    }
   ],
   "source": [
    "print(cur_segmented_sentences[0])\n",
    "\n",
    "# # To evaluate gold segmentation:\n",
    "# cur_segmented_sentences = prepared_text_gold[:n_eval_utterances]\n",
    "# print(cur_segmented_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5285it [00:00, 84995.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert segmentation to intervals\n",
    "segmentation_interval_dict = {}\n",
    "for i_utt, utt_key in tqdm(enumerate(eval_utterances)):\n",
    "    words_segmented = cur_segmented_sentences[i_utt].split(\" \")\n",
    "    word_start = 0\n",
    "    word_label = \"\"\n",
    "    i_word = 0\n",
    "    segmentation_interval_dict[utt_key] = []\n",
    "    for (phone_start, phone_end,\n",
    "            phone_label) in phoneseg_interval_dict[utt_key]:\n",
    "        word_label += phone_label + \"_\"\n",
    "        if words_segmented[i_word] == word_label[:-1]:\n",
    "            segmentation_interval_dict[utt_key].append((\n",
    "                word_start, phone_end, word_label[:-1]\n",
    "                ))\n",
    "            word_label = \"\"\n",
    "            word_start = phone_end\n",
    "            i_word += 1\n",
    "\n",
    "#     if i_utt < 10:\n",
    "#         print(segmentation_interval_dict[utt_key])\n",
    "#         print(word_ref_interval_dict[utt_key])\n",
    "#         print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1059/5285 [00:00<00:00, 8904.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to: ../../vqwordseg/exp/cpc_big/zs2017_zhtmp/train/wordseg_segaernn_dp_penalized/intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5285/5285 [00:00<00:00, 9877.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Write intervals to a directory\n",
    "output_tag = \"wordseg_segaernn_{}\".format(seg_tag.replace(\"phoneseg_\", \"\"))\n",
    "output_dir = (\n",
    "    Path(\"../../vqwordseg/exp\")/vq_model/dataset/split/output_tag/\"intervals\"\n",
    "    )\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"Writing to: {output_dir}\")\n",
    "for utt_key in tqdm(segmentation_interval_dict):\n",
    "    with open((output_dir/utt_key).with_suffix(\".txt\"), \"w\") as f:\n",
    "        for (i_segment, (start, end, label)) in enumerate(segmentation_interval_dict[utt_key]):\n",
    "            f.write(f\"{start:d} {end:d} {label}_\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
