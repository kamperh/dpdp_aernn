{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation on Xitsonga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2021 Herman Kamper, MIT License\n",
    "\n",
    "Train a segmental autoencoding recurrent neural network (segmental AE-RNN) and perform word segmentation on encoded Xitsonga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy.stats import gamma\n",
    "from sklearn import cluster\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from seg_aernn import datasets, models, viterbi\n",
    "from utils import eval_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented_sentence(ids, boundaries):\n",
    "    output = \"\"\n",
    "    cur_word = []\n",
    "    for i_symbol, boundary in enumerate(boundaries):\n",
    "        cur_word.append(id_to_symbol[ids[i_symbol]])\n",
    "        if boundary:\n",
    "            output += \"_\".join(cur_word)\n",
    "            output += \" \"\n",
    "            cur_word = []\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration penalty functions\n",
    "\n",
    "# Histogram\n",
    "histogram = np.array([\n",
    "    0, 1.66322800e-01, 2.35838129e-01, 2.10609187e-01,\n",
    "    1.48025482e-01, 9.42918160e-02, 5.84211098e-02, 3.64679480e-02,\n",
    "    2.18264741e-02, 1.25420784e-02, 7.18500018e-03, 4.27118399e-03,\n",
    "    1.73743077e-03, 1.19448366e-03, 7.42027726e-04, 2.89571796e-04,\n",
    "    2.35277084e-04, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001\n",
    "    ])  # to-do: check this\n",
    "histogram = histogram/np.sum(histogram)\n",
    "def neg_log_hist(dur):\n",
    "    return -np.log(0 if dur >= len(histogram) else histogram[dur])\n",
    "\n",
    "# Cached Gamma\n",
    "# shape, loc, scale = (2.3, 0, 1.3)  # VQ-VAE\n",
    "shape, loc, scale = (2.6, 0, 1.8)    # CPC-big\n",
    "# shape, loc, scale = (2.5, 0, 1.5)    # CPC-big (Gamma)\n",
    "gamma_cache = []\n",
    "for dur in range(200):\n",
    "    gamma_cache.append(gamma.pdf(dur, shape, loc, scale))\n",
    "gamma_cache = np.array(gamma_cache)/np.sum(gamma_cache)\n",
    "def neg_log_gamma(dur):\n",
    "    if dur < 200:\n",
    "        return -np.log(gamma_cache[dur])\n",
    "    else:\n",
    "        return -np.log(0)\n",
    "    \n",
    "# Chorowski\n",
    "def neg_chorowski(dur):\n",
    "    return -(dur - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "vq_model = \"cpc_big\"\n",
    "# vq_model = \"xlsr\"\n",
    "dataset = \"xitsonga\"\n",
    "split = \"train\"\n",
    "seg_tag = \"phoneseg_dp_penalized\"\n",
    "\n",
    "# Paths\n",
    "seg_dir = (\n",
    "    Path(\"../../vqwordseg/exp\")/vq_model/dataset/split/seg_tag/\"intervals\"\n",
    "    )\n",
    "word_ref_dir = Path(\"../../vqwordseg/data\")/dataset/\"word_intervals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/4058 [00:00<00:42, 95.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../../vqwordseg/exp/cpc_big/xitsonga/train/phoneseg_dp_penalized/intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4058/4058 [00:39<00:00, 103.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read phone segmentation\n",
    "phoneseg_interval_dict = {}\n",
    "print(\"Reading: {}\".format(seg_dir))\n",
    "phoneseg_interval_dict = eval_segmentation.get_intervals_from_dir(seg_dir)\n",
    "utterances = phoneseg_interval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4058 [00:00<06:47,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../../vqwordseg/data/xitsonga/word_intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4058/4058 [00:58<00:00, 69.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read word reference\n",
    "print(\"Reading: {}\".format(word_ref_dir))\n",
    "word_ref_interval_dict = eval_segmentation.get_intervals_from_dir(word_ref_dir, utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4058/4058 [00:00<00:00, 877299.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. word types: 2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_types = set()\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    for start, end, label in word_ref_interval_dict[utt_key]:\n",
    "        word_types.add(label)\n",
    "print(\"No. word types:\", len(word_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4058/4058 [00:00<00:00, 283740.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert intervals to boundaries\n",
    "word_ref_boundaries_dict = {}\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    word_ref_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        word_ref_interval_dict[utt_key]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4058/4058 [00:00<00:00, 404787.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_15_9_44_14_1_34_18_6_44_14_24_5_37_20_9_44_32_46_14_1_10_44_14_24_5_40_47_15_6_44_14_1_21_25_36_39_47_24_15_41_44_14_47_24_29_36_40_33_44_25_14_17_40_14_47_24_15_27_23_17_27_38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepared_text = []\n",
    "for utt_key in tqdm(utterances):\n",
    "    prepared_text.append(\n",
    "        \"_\".join([i[2] for i in phoneseg_interval_dict[utt_key]])\n",
    "        )\n",
    "print(prepared_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4058/4058 [00:00<00:00, 16435.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_15_9_44_14_1_34_18_6_44_14 24_5 37_20_9_44_32_46 14_1_10_44_14 24_5_40 47_15_6_44_14_1_21_25 36_39_47_24_15_41_44_14 47_24_29_36_40_33_44_25 14_17_40_14_47_24_15_27_23_17_27_38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gold segmentation, where boundaries are inserted in best possible positions\n",
    "n_not_in_tolerance = 0\n",
    "prepared_text_gold = []\n",
    "for utt_key in tqdm(utterances):\n",
    "    seg_intervals = phoneseg_interval_dict[utt_key].copy()\n",
    "    ref_intervals = word_ref_interval_dict[utt_key].copy()\n",
    "    seg_boundaries = np.array([i[1] - 1 for i in seg_intervals])\n",
    "    ref_boundaries = np.array([i[1] - 1 for i in ref_intervals])\n",
    "    for ref_boundary in ref_boundaries[:-1]:\n",
    "        i_seg = np.argmin(np.abs(seg_boundaries - ref_boundary))\n",
    "        seg_intervals.insert(\n",
    "            i_seg + 1, (seg_intervals[i_seg][1], seg_intervals[i_seg][1], \" \")\n",
    "            )\n",
    "        seg_boundaries = np.array([i[1] - 1 for i in seg_intervals])\n",
    "    cur_text_gold = \"\"\n",
    "    for start, end, label in seg_intervals:\n",
    "        if label == \" \":\n",
    "            cur_text_gold = cur_text_gold[:-1]\n",
    "            cur_text_gold += \" \"\n",
    "        else:\n",
    "            cur_text_gold += label + \"_\"\n",
    "    cur_text_gold = cur_text_gold[:-1]\n",
    "    prepared_text_gold.append(cur_text_gold)\n",
    "\n",
    "print(prepared_text_gold[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. word types: 15107\n",
      "Mean training word length: 8.3187\n",
      "Min training word length:  1\n",
      "Max training word length:  36\n",
      "Mean: 8.318743381574302\n",
      "Gamma parameters: 2.457785860462573 0 3.3846493770651986\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training word length statistics\n",
    "word_lengths = []\n",
    "n_words = []\n",
    "word_types = set()\n",
    "for sentence in prepared_text_gold:\n",
    "    word_lengths.extend([len(i.split(\"_\")) for i in sentence.split(\" \")])\n",
    "    n_words.append(len(sentence.split(\" \")))\n",
    "    for word in sentence.split(\" \"):\n",
    "        word_types.add(word)\n",
    "#     word_lengths.extend([len(i.replace(\"$\", \"\")) for i in sentence.split(\" \")])  # temp\n",
    "print(\"No. word types:\", len(word_types))\n",
    "print(\"Mean training word length: {:.4f}\".format(np.mean(word_lengths)))\n",
    "print(\"Min training word length:  {:d}\".format(np.min(word_lengths)))\n",
    "print(\"Max training word length:  {:d}\".format(np.max(word_lengths)))\n",
    "\n",
    "# Histogram\n",
    "plt.figure()\n",
    "n, bins, patches = plt.hist(word_lengths, bins=range(20), density=True)\n",
    "plt.title(\"Word lengths\")\n",
    "\n",
    "# Gamma\n",
    "mean = np.mean(word_lengths)\n",
    "var  = np.var(word_lengths)\n",
    "alpha = (mean**2)/var\n",
    "beta  = alpha / mean\n",
    "shape = alpha\n",
    "loc = 0\n",
    "scale = 1/beta\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Gamma parameters:\", shape, loc, scale)\n",
    "shape, loc, scale = (2.6, 0, 1.8)\n",
    "plt.plot(bins, gamma.pdf(bins, shape, loc, scale))\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 11, 53, 43, 10, 5, 32, 14, 50, 43, 10, 21, 49, 35, 17, 53, 43, 30, 45, 10, 5, 6, 43, 10, 21, 49, 39, 46, 11, 50, 43, 10, 5, 18, 22, 34, 37, 46, 21, 11, 40, 43, 10, 46, 21, 26, 34, 39, 31, 43, 22, 10, 13, 39, 10, 46, 21, 11, 24, 20, 13, 24, 36]\n",
      "['13', '15', '9', '44', '14', '1', '34', '18', '6', '44', '14', '24', '5', '37', '20', '9', '44', '32', '46', '14', '1', '10', '44', '14', '24', '5', '40', '47', '15', '6', '44', '14', '1', '21', '25', '36', '39', '47', '24', '15', '41', '44', '14', '47', '24', '29', '36', '40', '33', '44', '25', '14', '17', '40', '14', '47', '24', '15', '27', '23', '17', '27', '38']\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary\n",
    "PAD_SYMBOL      = \"<pad>\"\n",
    "SOS_SYMBOL      = \"<s>\"    # start of sentence\n",
    "EOS_SYMBOL      = \"</s>\"   # end of sentence\n",
    "BOUNDARY_SYMBOL = \" \"      # word boundary\n",
    "symbols = set()\n",
    "for sentence in prepared_text:\n",
    "    for char in sentence.split(\"_\"):\n",
    "        symbols.add(char)\n",
    "SYMBOLS = [PAD_SYMBOL, SOS_SYMBOL, EOS_SYMBOL, BOUNDARY_SYMBOL] + (sorted(list(symbols)))\n",
    "symbol_to_id = {s: i for i, s in enumerate(SYMBOLS)}\n",
    "id_to_symbol = {i: s for i, s in enumerate(SYMBOLS)}\n",
    "\n",
    "def text_to_id(text, add_sos_eos=False):\n",
    "    \"\"\"\n",
    "    Convert text to a list of symbol IDs.\n",
    "\n",
    "    Sentence start and end symbols can be added by setting `add_sos_eos`.\n",
    "    \"\"\"\n",
    "    symbol_ids = []\n",
    "    for word in text.split(\" \"):\n",
    "        for code in word.split(\"_\"):\n",
    "            symbol_ids.append(symbol_to_id[code])\n",
    "        symbol_ids.append(symbol_to_id[BOUNDARY_SYMBOL])\n",
    "    symbol_ids = symbol_ids[:-1]  # remove last space\n",
    "\n",
    "    if add_sos_eos:\n",
    "        return [symbol_to_id[SOS_SYMBOL]] + symbol_ids + [symbol_to_id[EOS_SYMBOL]]\n",
    "    else:\n",
    "        return symbol_ids\n",
    "\n",
    "print(text_to_id(prepared_text[0]))\n",
    "print([id_to_symbol[i] for i in text_to_id(prepared_text[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_15_9_44_14_1_34_18_6_44_14_24_5_37_20_9_44_32_46_14_1_10_44_14_24_5_40_47_15_6_44_14_1_21_25_36_39_47_24_15_41_44_14_47_24_29_36_40_33_44_25_14_17_40_14_47_24_15_27_23_17_27_38\n",
      "13_27_23_40_21_45_14_37_18_20_6_42_49_10_44_14_26_6_44_45_14_47_1_10_27_2_46_40_21_44_16_38\n",
      "13_20_6_35_47_15_9_11_45_14_33_36_48_14_1_10_44_14_33_44_14_47_24_15_27_23_33_5_43\n",
      "13_34_24_29_36_0_33_10_27_23_37_18_6_44_25_39_45_14_10_42_47_24_41_44_14_10_21_45_14_10_42_47_24_41_27_47_24_29_42_37_18_20_6_42_25_36_39_2_23_24_29_46\n",
      "31_24_33_44_45_37_18_20_6_11_2_1_10_46_43_28_1_15_9_44_14_49_34_10_44_45_14_1_10_36_39_14_33_10_27_37_18_20_6_44_45_25_40_34\n",
      "13_35_23_24_29_36_39_35_46_25_36_39_2_46_14_1_10_25_17_24_5_40_33_34_5_35_23_47_24_40_34\n",
      "13_24_5_27_16_20_9_27_23_49_10_45_14_37_18_20_27_46_17_36_39_14_47_24_15_27_46_37_18_20_6_21_42_37_18_20_9_44_45\n"
     ]
    }
   ],
   "source": [
    "# First three words of training data\n",
    "word_dataset = datasets.WordDataset(prepared_text, text_to_id)\n",
    "for i in range(7):\n",
    "    sample = word_dataset[i]\n",
    "    print(\"_\".join([id_to_symbol[i] for i in sample.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. train sentences: 4058\n",
      "Examples: ['13_15_9_44_14_1_34_18_6_44_14_24_5_37_20_9_44_32_46_14_1_10_44_14_24_5_40_47_15_6_44_14_1_21_25_36_39_47_24_15_41_44_14_47_24_29_36_40_33_44_25_14_17_40_14_47_24_15_27_23_17_27_38', '13_27_23_40_21_45_14_37_18_20_6_42_49_10_44_14_26_6_44_45_14_47_1_10_27_2_46_40_21_44_16_38', '13_20_6_35_47_15_9_11_45_14_33_36_48_14_1_10_44_14_33_44_14_47_24_15_27_23_33_5_43']\n",
      "Min length:  4\n",
      "Max length:  96\n",
      "Mean length: 40.6528\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "# Approximate ground truth (for debugging)\n",
    "# cur_train_sentences = prepared_text_gold[:10000]\n",
    "cur_val_sentences = prepared_text_gold[-100:]\n",
    "\n",
    "# No boundaries\n",
    "# cur_train_sentences = prepared_text[:10000]\n",
    "cur_train_sentences = prepared_text\n",
    "\n",
    "# Random boundaries\n",
    "np.random.seed(42)\n",
    "# cur_train_sentences = insert_random_boundaries(cur_train_sentences)\n",
    "# cur_val_sentences = insert_random_boundaries(cur_val_sentences)\n",
    "\n",
    "print(\"No. train sentences:\", len(cur_train_sentences))\n",
    "print(\"Examples:\", cur_train_sentences[:3])\n",
    "print(\"Min length: \", min([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Max length: \", max([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Mean length: {:.4f}\".format(np.mean([len(i.split(\"_\")) for i in cur_train_sentences])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(i.split(\"_\")) for i in cur_train_sentences], 50, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE-RNN model\n",
    "n_symbols = len(SYMBOLS)\n",
    "symbol_embedding_dim = 10  # 25\n",
    "hidden_dim = 500  # 250  # 500  # 1000  # 200\n",
    "embedding_dim = 50  # 150  # 300  # 25\n",
    "teacher_forcing_ratio = 0.5  # 1.0  # 0.5  # 1.0\n",
    "n_encoder_layers = 1  # 1  # 3  # 10\n",
    "n_decoder_layers = 1  # 1  # 1\n",
    "batch_size = 32  # 32*3  # 32\n",
    "learning_rate = 0.001\n",
    "input_dropout = 0.0  # 0.0 # 0.5\n",
    "dropout = 0.0\n",
    "n_symbols_max = 50  # test\n",
    "# n_epochs_max = 5\n",
    "n_epochs_max = None  # determined from n_max_steps and batch size\n",
    "n_steps_max = 1500  # 2500  # 1500  # 1000  # None\n",
    "# n_steps_max = None  # Only use n_epochs_max\n",
    "bidirectional_encoder = False  # False\n",
    "\n",
    "encoder = models.Encoder(\n",
    "    n_symbols=n_symbols,\n",
    "    symbol_embedding_dim=symbol_embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_encoder_layers,\n",
    "    dropout=dropout,\n",
    "    input_dropout=input_dropout,\n",
    "    bidirectional=bidirectional_encoder\n",
    "    )\n",
    "# decoder = models.Decoder1(\n",
    "#     n_symbols=n_symbols,\n",
    "#     symbol_embedding_dim=symbol_embedding_dim,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     n_layers=n_decoder_layers,\n",
    "#     sos_id = symbol_to_id[SOS_SYMBOL],\n",
    "#     teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "#     dropout=dropout\n",
    "#     )\n",
    "decoder = models.Decoder2(\n",
    "    n_symbols=n_symbols,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_decoder_layers,\n",
    "    dropout=dropout\n",
    "    )\n",
    "model = models.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:03<00:00, 31.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 137.541, val loss: 29.130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:04<00:00, 31.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 132.255, val loss: 28.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 127/127 [00:04<00:00, 30.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 129.908, val loss: 26.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:04<00:00, 30.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 127.428, val loss: 25.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:04<00:00, 30.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss: 125.089, val loss: 25.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 127/127 [00:04<00:00, 30.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss: 122.971, val loss: 24.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:04<00:00, 31.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, train loss: 121.024, val loss: 23.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 127/127 [00:04<00:00, 29.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, train loss: 118.827, val loss: 23.260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:04<00:00, 31.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train loss: 116.190, val loss: 22.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 127/127 [00:04<00:00, 31.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, train loss: 114.207, val loss: 22.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 127/127 [00:03<00:00, 31.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train loss: 112.498, val loss: 23.520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 102/127 [00:03<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, train loss: 111.077, val loss: 21.798\n"
     ]
    }
   ],
   "source": [
    "# Training device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Training data\n",
    "train_dataset = datasets.WordDataset(\n",
    "    cur_train_sentences, text_to_id, n_symbols_max=n_symbols_max\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Validation data\n",
    "val_dataset = datasets.WordDataset(cur_val_sentences, text_to_id)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Loss\n",
    "criterion = nn.NLLLoss(\n",
    "    reduction=\"sum\", ignore_index=symbol_to_id[PAD_SYMBOL]\n",
    "    )\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "if n_epochs_max is None:\n",
    "    steps_per_epoch = np.ceil(len(cur_train_sentences)/batch_size)\n",
    "    n_epochs_max = int(np.ceil(n_steps_max/steps_per_epoch))\n",
    "\n",
    "i_step = 0\n",
    "for i_epoch in range(n_epochs_max):\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        optimiser.zero_grad()\n",
    "        data = data.to(device)       \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_output.contiguous().view(-1, decoder_output.size(-1)),\n",
    "            data.contiguous().view(-1)\n",
    "            )\n",
    "        loss /= len(data_lengths)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        train_losses.append(loss.item())\n",
    "        i_step += 1\n",
    "        if i_step == n_steps_max and n_steps_max is not None:\n",
    "            break\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "            data = data.to(device)            \n",
    "            encoder_embedding, decoder_output = model(\n",
    "                data, data_lengths, data, data_lengths\n",
    "                )\n",
    "\n",
    "            loss = criterion(\n",
    "                decoder_output.contiguous().view(-1,\n",
    "                decoder_output.size(-1)), data.contiguous().view(-1)\n",
    "                )\n",
    "            loss /= len(data_lengths)\n",
    "            val_losses.append(loss.item())\n",
    "    \n",
    "    print(\n",
    "        \"Epoch {}, train loss: {:.3f}, val loss: {:.3f}\".format(\n",
    "        i_epoch,\n",
    "        np.mean(train_losses),\n",
    "        np.mean(val_losses))\n",
    "        )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if i_step == n_steps_max and n_steps_max is not None:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  2_46\n",
      "Output: 46_46_46_46_46_23_23_23_23_23_23_23_19_19_19_46_46_46_46_46_46_46_46_46_23\n",
      "\n",
      "Input:  47_24_15_35_49_34_18_20_6_35_23_33_34_38\n",
      "Output: 13_20_20_6_35_37_37_20_9_35_35_38_38_38_38_38_38_38_38_38_38_38_35_35_23\n",
      "\n",
      "Input:  1_10_27_23\n",
      "Output: 13_27_27_27_27_23_23_23_23_23_23_23_23_23_23_23_23_27_27_27_23_23_23_23_23\n",
      "\n",
      "Input:  26_5_27_23_47_24_29_44_0_14_38\n",
      "Output: 13_29_39_14_47_24_24_29_44_44_44_38_38_38_38_38_38_38_38_38_38_38_38_38_38\n",
      "\n",
      "Input:  27_46_25\n",
      "Output: 27_27_46_46_25_25_25_25_25_25_25_25_25_25_25_25_25_25_25_25_27_27_27_27_46\n",
      "\n",
      "Input:  13_27_37_26_5_44_0_14_33_36_32_14\n",
      "Output: 13_33_14_14_14_44_44_25_25_25_40_14_34_34_40_40_12_12_12_12_13_13_34_34_34\n",
      "\n",
      "Input:  43_28_14_1_34_15_41_44\n",
      "Output: 13_28_41_14_14_14_14_43_45_38_38_38_38_13_13_28_14_14_14_14_14_43_43_38_38\n",
      "\n",
      "Input:  17_24_36\n",
      "Output: 13_36_36_17_17_24_36_36_36_36_36_36_36_36_36_36_36_36_36_36_36_36_36_36_36\n",
      "\n",
      "Input:  17_36_39_35_23_1_10\n",
      "Output: 13_1_39_1_1_1_1_1_1_1_1_38_38_38_38_38_34_1_1_1_1_1_1_1_1\n",
      "\n",
      "Input:  13_35_23\n",
      "Output: 35_35_35_35_35_23_23_23_23_23_23_23_23_23_35_35_35_35_35_35_35_35_35_35_23\n",
      "\n",
      "Input:  13_15_5_36_40_33_36_44_0_14_1_40_21_14\n",
      "Output: 13_36_17_17_36_36_36_40_10_10_10_10_14_40_40_40_40_40_40_12_12_12_34_40_40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "        \n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            encoder_embedding,\n",
    "            max_length=25,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "        \n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"_\".join(input_symbols))\n",
    "            print(\"Output:\", \"_\".join(output_symbols))\n",
    "            print()\n",
    "            \n",
    "            if i_input == 10:\n",
    "                break\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances for evaluation\n",
    "n_eval_utterances = len(prepared_text)  # 1000  # 10000  # 1000\n",
    "# eval_sentences = prepared_text[-n_eval_utterances:]  # val sentences\n",
    "# eval_utterances = list(utterances)[-n_eval_utterances:]\n",
    "eval_sentences = prepared_text[:n_eval_utterances]\n",
    "eval_utterances = list(utterances)[:n_eval_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64023/64023 [06:47<00:00, 157.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = eval_sentences\n",
    "# sentences = cur_val_sentences\n",
    "interval_dataset = datasets.SentenceIntervalDataset(\n",
    "    sentences,\n",
    "    text_to_id,\n",
    "    join_char=\"_\"\n",
    "    )\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "eos = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss.cpu().numpy())\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4058/4058 [00:04<00:00, 957.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL: -91210.4204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Segment\n",
    "\n",
    "dur_weight = 3.0  # 3.0\n",
    "\n",
    "i_item = 0\n",
    "losses = []\n",
    "cur_segmented_sentences = []\n",
    "for i_sentence, intervals in enumerate(tqdm(interval_dataset.intervals)):\n",
    "    \n",
    "    # Costs for segment intervals\n",
    "    costs = np.inf*np.ones(len(intervals))\n",
    "    i_eos = intervals[-1][-1]\n",
    "    for i_seg, interval in enumerate(intervals):\n",
    "        if interval is None:\n",
    "            continue\n",
    "        i_start, i_end = interval\n",
    "        dur = i_end - i_start\n",
    "        assert dur == lengths[i_item]\n",
    "        eos = (i_end == i_eos)  # end-of-sequence\n",
    "        \n",
    "        # Chorowski\n",
    "        costs[i_seg] = (\n",
    "            rnn_losses[i_item]\n",
    "            + dur_weight*neg_chorowski(dur)\n",
    "            )\n",
    "        \n",
    "#         # Gamma\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*neg_log_gamma(dur)\n",
    "#             + np.log(np.sum(gamma_cache**dur_weight))\n",
    "#             )\n",
    "        \n",
    "#         # Poisson\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + neg_log_poisson(dur)\n",
    "#             )\n",
    "\n",
    "#         # Histogram\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*(neg_log_hist(dur))\n",
    "#             + np.log(np.sum(histogram**dur_weight))\n",
    "#             )\n",
    "    \n",
    "#         # Sequence boundary\n",
    "#         alpha = 0.3  # 0.3  # 0.9\n",
    "#         if eos:\n",
    "#             costs[i_seg] += -np.log(alpha)\n",
    "#         else:\n",
    "#             costs[i_seg] += -np.log(1 - alpha)\n",
    "# #             K = 5000\n",
    "# #             costs[i_seg] += -np.log((1 - alpha)/K)\n",
    "\n",
    "        # Temp\n",
    "#         if dur > 10 or dur <= 1:\n",
    "#             costs[i_seg] = +np.inf\n",
    "        i_item += 1\n",
    "    \n",
    "    # Viterbi segmentation\n",
    "    n_frames = len(interval_dataset.sentences[i_sentence])\n",
    "    summed_cost, boundaries = viterbi.custom_viterbi(costs, n_frames)\n",
    "    losses.append(summed_cost)\n",
    "    \n",
    "    reference_sentence = sentences[i_sentence]\n",
    "    segmented_sentence = get_segmented_sentence(\n",
    "            interval_dataset.sentences[i_sentence],\n",
    "            boundaries\n",
    "            )\n",
    "    cur_segmented_sentences.append(segmented_sentence)\n",
    "#     # Print examples of the first few sentences\n",
    "#     if i_sentence < 10:\n",
    "#         print(reference_sentence)\n",
    "#         print(segmented_sentence)\n",
    "#         print()\n",
    "    \n",
    "print(\"NLL: {:.4f}\".format(np.sum(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_15_9_44_14_1_34_18_6_44_14 24_5_37_20_9_44_32_46_14_1_10_44_14 24_5_40 47_15_6_44 14_1_21 25_36_39_47_24_15_41_44_14_47_24_29_36 40_33_44_25_14_17_40_14_47_24_15_27_23 17_27_38\n"
     ]
    }
   ],
   "source": [
    "print(cur_segmented_sentences[0])\n",
    "\n",
    "# # To evaluate gold segmentation:\n",
    "# cur_segmented_sentences = prepared_text_gold[:n_eval_utterances]\n",
    "# print(cur_segmented_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4058it [00:00, 61935.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 40, '13_15_9_44_14_1_34_18_6_44_14'), (40, 110, '24_5_37_20_9_44_32_46_14_1_10_44_14'), (110, 122, '24_5_40'), (122, 143, '47_15_6_44'), (143, 156, '14_1_21'), (156, 201, '25_36_39_47_24_15_41_44_14_47_24_29_36'), (201, 270, '40_33_44_25_14_17_40_14_47_24_15_27_23'), (270, 290, '17_27_38')]\n",
      "[(0, 40, 'dyondza'), (40, 52, 'ku'), (52, 91, 'hlaya'), (91, 109, 'na'), (109, 124, 'ku'), (124, 161, 'tsala'), (161, 187, 'uta'), (187, 220, 'kuma'), (220, 290, 'vutivi')]\n",
      "\n",
      "[(0, 21, '13_27'), (21, 121, '23_40_21_45_14_37_18_20_6_42_49_10_44_14_26'), (121, 137, '6_44_45_14'), (137, 209, '47_1_10_27_2_46_40_21_44_16_38')]\n",
      "[(0, 24, 'hi'), (24, 63, 'laha'), (63, 85, 'swi'), (85, 109, 'nga'), (109, 209, 'fanela')]\n",
      "\n",
      "[(0, 76, '13_20_6_35_47_15_9_11_45_14_33_36_48'), (76, 93, '14_1_10_44'), (93, 178, '14_33_44_14_47_24_15_27_23_33_5_43')]\n",
      "[(0, 78, 'swicelwa'), (78, 95, 'ni'), (95, 179, 'matimba')]\n",
      "\n",
      "[(0, 14, '13_34'), (14, 34, '24_29_36_0'), (34, 106, '33_10_27_23_37_18_6_44_25_39_45_14_10_42_47'), (106, 179, '24_41_44_14_10_21_45_14_10_42_47_24_41_27_47'), (179, 249, '24_29_42_37_18_20_6_42_25_36_39_2_23'), (249, 264, '24_29_46')]\n",
      "[(0, 73, 'nkomiso'), (73, 89, 'wa'), (89, 124, 'rito'), (124, 159, 'leri'), (159, 264, 'tikisiweke')]\n",
      "\n",
      "[(0, 1, '31'), (1, 75, '24_33_44_45_37_18_20_6_11_2_1_10_46_43_28'), (75, 108, '1_15_9_44_14_49'), (108, 126, '34_10_44_45_14_1'), (126, 193, '10_36_39_14_33_10_27_37_18_20_6_44_45'), (193, 226, '25_40_34')]\n",
      "[(0, 65, 'mafenya'), (65, 75, 'i'), (75, 132, 'nhlangano'), (132, 144, 'wa'), (144, 226, 'misawu')]\n",
      "\n",
      "[(0, 79, '13_35_23_24_29_36_39_35_46_25_36_39_2_46'), (79, 88, '14_1_10'), (88, 96, '25_17'), (96, 166, '24_5_40_33_34_5_35_23_47_24_40_34')]\n",
      "[(0, 32, 'nyiko'), (32, 47, 'ya'), (47, 93, 'wena'), (93, 133, 'kumbe'), (133, 166, 'ku')]\n",
      "\n",
      "[(0, 20, '13_24'), (20, 46, '5_27'), (46, 117, '16_20_9_27_23_49_10_45_14_37_18_20_27_46'), (117, 152, '17_36_39_14_47_24_15_27_46'), (152, 214, '37_18_20_6_21_42_37_18_20_9_44_45')]\n",
      "[(0, 51, 'b'), (51, 78, 'xi'), (78, 94, 'na'), (94, 176, 'xivutiso'), (176, 214, 'xa')]\n",
      "\n",
      "[(0, 44, '13_10_21_44_25_17_24_29_44'), (44, 64, '14_33_10_1'), (64, 97, '24_15_41_42_14_40_21_42'), (97, 155, '14_40_21_44_14_33_34_18_6_36_40'), (155, 195, '33_36_39_32_14_37_18_20'), (195, 204, '9_27_23'), (204, 232, '24_5_36_30'), (232, 321, '34_10_27_23_18_20_6_44_0_43_28_0_16')]\n",
      "[(0, 45, 'loko'), (45, 170, 'mutirhelamfumo'), (170, 184, 'wa'), (184, 291, 'xiphorisa'), (291, 321, 'a')]\n",
      "\n",
      "[(0, 22, '13_12'), (22, 44, '13_36'), (44, 60, '3_37_18_20'), (60, 79, '22_36_39_32'), (79, 96, '43_24'), (96, 152, '13_42_37_18_20_22_44_25_40_10_42_14_1'), (152, 221, '34_15_35_23_33_5_44_14_16')]\n",
      "[(0, 77, 'vuswa'), (77, 108, 'i'), (108, 143, 'swava'), (143, 221, 'ntima')]\n",
      "\n",
      "[(0, 62, '13_15_41_44_45_25_36_40_21_42_14_17'), (62, 110, '9_27_46_3_36_16'), (110, 127, '26_38'), (127, 214, '13_33_10_42_30_25_40_1_10_25_40_38'), (214, 283, '13_10_25_3_36_43_28_32_14_1_34_18'), (283, 344, '6_42_37_18_20_6_42_3_40_39_2_23'), (344, 369, '24_29_43')]\n",
      "[(0, 13, 'ta'), (13, 126, 'holeriwa'), (126, 207, 'muholo'), (207, 257, 'lowu'), (257, 369, 'andzisiweke')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert segmentation to intervals\n",
    "segmentation_interval_dict = {}\n",
    "for i_utt, utt_key in tqdm(enumerate(eval_utterances)):\n",
    "    words_segmented = cur_segmented_sentences[i_utt].split(\" \")\n",
    "    word_start = 0\n",
    "    word_label = \"\"\n",
    "    i_word = 0\n",
    "    segmentation_interval_dict[utt_key] = []\n",
    "    for (phone_start, phone_end,\n",
    "            phone_label) in phoneseg_interval_dict[utt_key]:\n",
    "        word_label += phone_label + \"_\"\n",
    "        if words_segmented[i_word] == word_label[:-1]:\n",
    "            segmentation_interval_dict[utt_key].append((\n",
    "                word_start, phone_end, word_label[:-1]\n",
    "                ))\n",
    "            word_label = \"\"\n",
    "            word_start = phone_end\n",
    "            i_word += 1\n",
    "\n",
    "    if i_utt < 10:\n",
    "        print(segmentation_interval_dict[utt_key])\n",
    "        print(word_ref_interval_dict[utt_key])\n",
    "        print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4058/4058 [00:00<00:00, 256959.53it/s]\n",
      "100%|██████████| 4058/4058 [00:00<00:00, 247588.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Word boundaries:\n",
      "Precision: 20.59%\n",
      "Recall: 19.75%\n",
      "F-score: 20.16%\n",
      "OS: -4.06%\n",
      "R-value: 32.89%\n",
      "---------------------------------------------------------------------------\n",
      "Word token boundaries:\n",
      "Precision: 6.34%\n",
      "Recall: 6.14%\n",
      "F-score: 6.24%\n",
      "OS: -3.20%\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Intervals to boundaries\n",
    "segmentation_boundaries_dict = {}\n",
    "for utt_key in tqdm(segmentation_interval_dict):\n",
    "    segmentation_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        segmentation_interval_dict[utt_key]\n",
    "        )\n",
    "word_ref_boundaries_dict = {}\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    word_ref_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        word_ref_interval_dict[utt_key]\n",
    "        )\n",
    "\n",
    "# Evaluate word boundaries\n",
    "reference_list = []\n",
    "segmentation_list = []\n",
    "for utterance in segmentation_boundaries_dict:\n",
    "    reference_list.append(word_ref_boundaries_dict[utterance])\n",
    "    segmentation_list.append(segmentation_boundaries_dict[utterance])\n",
    "\n",
    "tolerance = 2\n",
    "p, r, f = eval_segmentation.score_boundaries(\n",
    "    reference_list, segmentation_list, tolerance=tolerance\n",
    "    )\n",
    "print(\"-\"*(79 - 4))\n",
    "print(\"Word boundaries:\")\n",
    "print(\"Precision: {:.2f}%\".format(p*100))\n",
    "print(\"Recall: {:.2f}%\".format(r*100))\n",
    "print(\"F-score: {:.2f}%\".format(f*100))\n",
    "print(\"OS: {:.2f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "print(\"R-value: {:.2f}%\".format(eval_segmentation.get_rvalue(p, r)*100))\n",
    "print(\"-\"*(79 - 4))\n",
    "\n",
    "p, r, f = eval_segmentation.score_word_token_boundaries(\n",
    "    reference_list, segmentation_list, tolerance=tolerance\n",
    "    )\n",
    "print(\"Word token boundaries:\")\n",
    "print(\"Precision: {:.2f}%\".format(p*100))\n",
    "print(\"Recall: {:.2f}%\".format(r*100))\n",
    "print(\"F-score: {:.2f}%\".format(f*100))\n",
    "print(\"OS: {:.2f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "# print(\"R-value: {:.2f}%\".format(get_rvalue(p, r)*100))\n",
    "print(\"-\"*(79 - 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1138/4058 [00:00<00:00, 11329.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to: ../../vqwordseg/exp/cpc_big/xitsonga/train/wordseg_segaernn_dp_penalized/intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4058/4058 [00:00<00:00, 10538.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Write intervals to a directory\n",
    "output_tag = \"wordseg_segaernn_{}\".format(seg_tag.replace(\"phoneseg_\", \"\"))\n",
    "output_dir = (\n",
    "    Path(\"../../vqwordseg/exp\")/vq_model/dataset/split/output_tag/\"intervals\"\n",
    "    )\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"Writing to: {output_dir}\")\n",
    "for utt_key in tqdm(segmentation_interval_dict):\n",
    "    with open((output_dir/utt_key).with_suffix(\".txt\"), \"w\") as f:\n",
    "        for (i_segment, (start, end, label)) in enumerate(segmentation_interval_dict[utt_key]):\n",
    "#             label = cluster_dict[utt_key][i_segment]\n",
    "            f.write(f\"{start:d} {end:d} {label}_\\n\")\n",
    "            \n",
    "#         for start, end, label in segmentation_interval_dict[utt_key]:\n",
    "# #             f.write(f\"{start:d} {end:d} {label}\\n\")\n",
    "#             f.write(f\"{start:d} {end:d} {label}_\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
