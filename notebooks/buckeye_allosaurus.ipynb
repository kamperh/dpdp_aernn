{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation on Buckeye Allosaurus Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herman Kamper, 2021\n",
    "\n",
    "Train a segmental autoencoding recurrent neural network (segmental AE-RNN) and perform word segmentation on encoded Buckeye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy.stats import gamma\n",
    "from sklearn import cluster\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from seg_aernn import datasets, models, viterbi\n",
    "from utils import eval_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented_sentence(ids, boundaries):\n",
    "    output = \"\"\n",
    "    cur_word = []\n",
    "    for i_symbol, boundary in enumerate(boundaries):\n",
    "        cur_word.append(id_to_symbol[ids[i_symbol]])\n",
    "        if boundary:\n",
    "            output += \"_\".join(cur_word)\n",
    "            output += \" \"\n",
    "            cur_word = []\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration penalty functions\n",
    "\n",
    "# Histogram\n",
    "histogram = np.array([\n",
    "    0, 1.66322800e-01, 2.35838129e-01, 2.10609187e-01,\n",
    "    1.48025482e-01, 9.42918160e-02, 5.84211098e-02, 3.64679480e-02,\n",
    "    2.18264741e-02, 1.25420784e-02, 7.18500018e-03, 4.27118399e-03,\n",
    "    1.73743077e-03, 1.19448366e-03, 7.42027726e-04, 2.89571796e-04,\n",
    "    2.35277084e-04, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001\n",
    "    ])  # to-do: check this\n",
    "histogram = histogram/np.sum(histogram)\n",
    "def neg_log_hist(dur):\n",
    "    return -np.log(0 if dur >= len(histogram) else histogram[dur])\n",
    "\n",
    "# Cached Gamma\n",
    "# shape, loc, scale = (2.3, 0, 1.3)  # VQ-VAE\n",
    "# shape, loc, scale = (2.6, 0, 1.8)    # CPC-big\n",
    "shape, loc, scale = (2.3, 0, 1.5)    # Allosaurus\n",
    "gamma_cache = []\n",
    "for dur in range(200):\n",
    "    gamma_cache.append(gamma.pdf(dur, shape, loc, scale))\n",
    "gamma_cache = np.array(gamma_cache)/np.sum(gamma_cache)\n",
    "def neg_log_gamma(dur):\n",
    "    if dur < 200:\n",
    "        return -np.log(gamma_cache[dur])\n",
    "    else:\n",
    "        return -np.log(0)\n",
    "    \n",
    "# Chorowski\n",
    "def neg_chorowski(dur):\n",
    "    return -(dur - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = \"buckeye\"\n",
    "split = \"val\"\n",
    "seg_tag = \"emit1.2\"\n",
    "# seg_tag = \"eng_emit1.2\"\n",
    "\n",
    "# Paths\n",
    "seg_dir = (\n",
    "    Path(\"../../allosaurus/exp/allosaurus\")/dataset/split/seg_tag/\"intervals\"\n",
    "    )\n",
    "word_ref_dir = Path(\"../../vqwordseg/data\")/dataset/\"word_intervals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 2723/16582 [00:00<00:00, 27222.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../../allosaurus/exp/allosaurus/buckeye/val/emit1.2/intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16582/16582 [00:00<00:00, 26709.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read phone segmentation\n",
    "phoneseg_interval_dict = {}\n",
    "print(\"Reading: {}\".format(seg_dir))\n",
    "phoneseg_interval_dict = eval_segmentation.get_intervals_from_dir(seg_dir)\n",
    "utterances = phoneseg_interval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16582 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../../vqwordseg/data/buckeye/word_intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16582/16582 [00:00<00:00, 31018.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read word reference\n",
    "print(\"Reading: {}\".format(word_ref_dir))\n",
    "word_ref_interval_dict = eval_segmentation.get_intervals_from_dir(word_ref_dir, utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16582/16582 [00:00<00:00, 988543.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. word types: 4057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_types = set()\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    for start, end, label in word_ref_interval_dict[utt_key]:\n",
    "        word_types.add(label)\n",
    "print(\"No. word types:\", len(word_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16582/16582 [00:00<00:00, 304505.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert intervals to boundaries\n",
    "word_ref_boundaries_dict = {}\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    word_ref_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        word_ref_interval_dict[utt_key]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16582/16582 [00:00<00:00, 695103.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð_ɒ_s̪_tʰ_e_ɛ_ʀ_ɒ_n_s̪_ɾ_e_ə\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepared_text = []\n",
    "for utt_key in tqdm(utterances):\n",
    "    prepared_text.append(\n",
    "        \"_\".join([i[2] for i in phoneseg_interval_dict[utt_key]])\n",
    "        )\n",
    "    \n",
    "print(prepared_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16582/16582 [00:00<00:00, 33613.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð_ɒ_s̪ tʰ_e_ɛ_ʀ_ɒ_n_s̪ ɾ_e_ə\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gold segmentation, where boundaries are inserted in best possible positions\n",
    "n_not_in_tolerance = 0\n",
    "prepared_text_gold = []\n",
    "for utt_key in tqdm(utterances):\n",
    "    seg_intervals = phoneseg_interval_dict[utt_key].copy()\n",
    "    ref_intervals = word_ref_interval_dict[utt_key].copy()\n",
    "    seg_boundaries = np.array([i[1] - 1 for i in seg_intervals])\n",
    "    ref_boundaries = np.array([i[1] - 1 for i in ref_intervals])\n",
    "    for ref_boundary in ref_boundaries[:-1]:\n",
    "        i_seg = np.argmin(np.abs(seg_boundaries - ref_boundary))\n",
    "        seg_intervals.insert(\n",
    "            i_seg + 1, (seg_intervals[i_seg][1], seg_intervals[i_seg][1], \" \")\n",
    "            )\n",
    "        seg_boundaries = np.array([i[1] - 1 for i in seg_intervals])\n",
    "    cur_text_gold = \"\"\n",
    "    for start, end, label in seg_intervals:\n",
    "        if label == \" \":\n",
    "            cur_text_gold = cur_text_gold[:-1]\n",
    "            cur_text_gold += \" \"\n",
    "        else:\n",
    "            cur_text_gold += label + \"_\"\n",
    "    cur_text_gold = cur_text_gold[:-1]\n",
    "    prepared_text_gold.append(cur_text_gold)\n",
    "\n",
    "print(prepared_text_gold[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. word types: 26710\n",
      "Mean training word length: 3.4085\n",
      "Min training word length:  1\n",
      "Max training word length:  19\n",
      "Mean: 3.408532176428055\n",
      "Gamma parameters: 2.344851022353912 0 1.4536241935772756\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training word length statistics\n",
    "word_lengths = []\n",
    "n_words = []\n",
    "word_types = set()\n",
    "for sentence in prepared_text_gold:\n",
    "    word_lengths.extend([len(i.split(\"_\")) for i in sentence.split(\" \")])\n",
    "    n_words.append(len(sentence.split(\" \")))\n",
    "    for word in sentence.split(\" \"):\n",
    "        word_types.add(word)\n",
    "#     word_lengths.extend([len(i.replace(\"$\", \"\")) for i in sentence.split(\" \")])  # temp\n",
    "print(\"No. word types:\", len(word_types))\n",
    "print(\"Mean training word length: {:.4f}\".format(np.mean(word_lengths)))\n",
    "print(\"Min training word length:  {:d}\".format(np.min(word_lengths)))\n",
    "print(\"Max training word length:  {:d}\".format(np.max(word_lengths)))\n",
    "\n",
    "# Histogram\n",
    "plt.figure()\n",
    "n, bins, patches = plt.hist(word_lengths, bins=range(20), density=True)\n",
    "plt.title(\"Word lengths\")\n",
    "\n",
    "# Gamma\n",
    "mean = np.mean(word_lengths)\n",
    "var  = np.var(word_lengths)\n",
    "alpha = (mean**2)/var\n",
    "beta  = alpha / mean\n",
    "shape = alpha\n",
    "loc = 0\n",
    "scale = 1/beta\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Gamma parameters:\", shape, loc, scale)\n",
    "# shape, loc, scale = (2.6, 0, 1.8)\n",
    "plt.plot(bins, gamma.pdf(bins, shape, loc, scale))\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78, 85, 49, 58, 17, 91, 113, 85, 38, 49, 111, 17, 90]\n",
      "['ð', 'ɒ', 's̪', 'tʰ', 'e', 'ɛ', 'ʀ', 'ɒ', 'n', 's̪', 'ɾ', 'e', 'ə']\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary\n",
    "PAD_SYMBOL      = \"<pad>\"\n",
    "SOS_SYMBOL      = \"<s>\"    # start of sentence\n",
    "EOS_SYMBOL      = \"</s>\"   # end of sentence\n",
    "BOUNDARY_SYMBOL = \" \"      # word boundary\n",
    "symbols = set()\n",
    "for sentence in prepared_text:\n",
    "    for char in sentence.split(\"_\"):\n",
    "        symbols.add(char)\n",
    "SYMBOLS = [PAD_SYMBOL, SOS_SYMBOL, EOS_SYMBOL, BOUNDARY_SYMBOL] + (sorted(list(symbols)))\n",
    "symbol_to_id = {s: i for i, s in enumerate(SYMBOLS)}\n",
    "id_to_symbol = {i: s for i, s in enumerate(SYMBOLS)}\n",
    "\n",
    "def text_to_id(text, add_sos_eos=False):\n",
    "    \"\"\"\n",
    "    Convert text to a list of symbol IDs.\n",
    "\n",
    "    Sentence start and end symbols can be added by setting `add_sos_eos`.\n",
    "    \"\"\"\n",
    "    symbol_ids = []\n",
    "    for word in text.split(\" \"):\n",
    "        for code in word.split(\"_\"):\n",
    "            symbol_ids.append(symbol_to_id[code])\n",
    "        symbol_ids.append(symbol_to_id[BOUNDARY_SYMBOL])\n",
    "    symbol_ids = symbol_ids[:-1]  # remove last space\n",
    "\n",
    "    if add_sos_eos:\n",
    "        return [symbol_to_id[SOS_SYMBOL]] + symbol_ids + [symbol_to_id[EOS_SYMBOL]]\n",
    "    else:\n",
    "        return symbol_ids\n",
    "\n",
    "print(text_to_id(prepared_text[0]))\n",
    "print([id_to_symbol[i] for i in text_to_id(prepared_text[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð_ɒ_s̪_tʰ_e_ɛ_ʀ_ɒ_n_s̪_ɾ_e_ə\n",
      "ʔ_ɒ\n",
      "ɴ_ɨ_ə_w_ɒ_e_n_ɴ_uə_a_ɒ_ɳ_ɴ_o_ɪ_e\n",
      "None\n",
      "ɾʲ_ə_t̪_t_ə_ɕ_uː_ə_ʂ_uə_ʁ_uː_z_t_ə_f_a_ɪ_t_ə\n",
      "ɒ_n_ɳ_n_ɒ_t̪_t͡ɕ_o_uə_z\n",
      "k_æ_f_t_ə_d_b̥_i_e_ə_b̞_ʌ_ɾ_ə_t_ɹ_ʌ_s_t\n"
     ]
    }
   ],
   "source": [
    "# First three words of training data\n",
    "word_dataset = datasets.WordDataset(prepared_text, text_to_id)\n",
    "for i in range(7):\n",
    "    sample = word_dataset[i]\n",
    "    print(\"_\".join([id_to_symbol[i] for i in sample.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. train sentences: 10000\n",
      "Examples: ['ð_ɒ_s̪_tʰ_e_ɛ_ʀ_ɒ_n_s̪_ɾ_e_ə', 'ʔ_ɒ', 'ɴ_ɨ_ə_w_ɒ_e_n_ɴ_uə_a_ɒ_ɳ_ɴ_o_ɪ_e']\n",
      "Min length:  1\n",
      "Max length:  95\n",
      "Mean length: 11.0467\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "# Approximate ground truth (for debugging)\n",
    "# cur_train_sentences = prepared_text_gold[:10000]\n",
    "cur_val_sentences = prepared_text_gold[-1000:]\n",
    "\n",
    "# No boundaries\n",
    "cur_train_sentences = prepared_text[:10000]\n",
    "# cur_val_sentences = prepared_text[-1000:]\n",
    "\n",
    "# Random boundaries\n",
    "np.random.seed(42)\n",
    "# cur_train_sentences = insert_random_boundaries(cur_train_sentences)\n",
    "# cur_val_sentences = insert_random_boundaries(cur_val_sentences)\n",
    "\n",
    "print(\"No. train sentences:\", len(cur_train_sentences))\n",
    "print(\"Examples:\", cur_train_sentences[:3])\n",
    "print(\"Min length: \", min([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Max length: \", max([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Mean length: {:.4f}\".format(np.mean([len(i.split(\"_\")) for i in cur_train_sentences])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE-RNN model\n",
    "n_symbols = len(SYMBOLS)\n",
    "symbol_embedding_dim = 10  # 25\n",
    "hidden_dim = 500  # 250  # 500  # 1000  # 200\n",
    "embedding_dim = 50  # 150  # 300  # 25\n",
    "teacher_forcing_ratio = 0.5  # 1.0  # 0.5  # 1.0\n",
    "n_encoder_layers = 1  # 1  # 3  # 10\n",
    "n_decoder_layers = 1  # 1  # 1\n",
    "batch_size = 32  # 32*3  # 32\n",
    "learning_rate = 0.001\n",
    "input_dropout = 0.0  # 0.0 # 0.5\n",
    "dropout = 0.0\n",
    "n_symbols_max = 25\n",
    "n_epochs_max = 5\n",
    "bidirectional_encoder = False  # False\n",
    "\n",
    "encoder = models.Encoder(\n",
    "    n_symbols=n_symbols,\n",
    "    symbol_embedding_dim=symbol_embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_encoder_layers,\n",
    "    dropout=dropout,\n",
    "    input_dropout=input_dropout,\n",
    "    bidirectional=bidirectional_encoder\n",
    "    )\n",
    "# decoder = models.Decoder1(\n",
    "#     n_symbols=n_symbols,\n",
    "#     symbol_embedding_dim=symbol_embedding_dim,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     n_layers=n_decoder_layers,\n",
    "#     sos_id = symbol_to_id[SOS_SYMBOL],\n",
    "#     teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "#     dropout=dropout\n",
    "#     )\n",
    "decoder = models.Decoder2(\n",
    "    n_symbols=n_symbols,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_decoder_layers,\n",
    "    dropout=dropout\n",
    "    )\n",
    "model = models.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 37.072, val loss: 11.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 33.183, val loss: 8.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 31.224, val loss: 7.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 29.181, val loss: 6.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss: 27.368, val loss: 5.367\n"
     ]
    }
   ],
   "source": [
    "# Training device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Training data\n",
    "train_dataset = datasets.WordDataset(\n",
    "    cur_train_sentences, text_to_id, n_symbols_max=n_symbols_max\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Validation data\n",
    "val_dataset = datasets.WordDataset(cur_val_sentences, text_to_id)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Loss\n",
    "criterion = nn.NLLLoss(\n",
    "    reduction=\"sum\", ignore_index=symbol_to_id[PAD_SYMBOL]\n",
    "    )\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i_epoch in range(n_epochs_max):\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        optimiser.zero_grad()\n",
    "        data = data.to(device)       \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_output.contiguous().view(-1, decoder_output.size(-1)),\n",
    "            data.contiguous().view(-1)\n",
    "            )\n",
    "        loss /= len(data_lengths)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "            data = data.to(device)            \n",
    "            encoder_embedding, decoder_output = model(\n",
    "                data, data_lengths, data, data_lengths\n",
    "                )\n",
    "\n",
    "            loss = criterion(\n",
    "                decoder_output.contiguous().view(-1,\n",
    "                decoder_output.size(-1)), data.contiguous().view(-1)\n",
    "                )\n",
    "            loss /= len(data_lengths)\n",
    "            val_losses.append(loss.item())\n",
    "    \n",
    "    print(\n",
    "        \"Epoch {}, train loss: {:.3f}, val loss: {:.3f}\".format(\n",
    "        i_epoch,\n",
    "        np.mean(train_losses),\n",
    "        np.mean(val_losses))\n",
    "        )\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  ə\n",
      "Output: ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə_ə\n",
      "\n",
      "Input:  n_ɑ_tʰ\n",
      "Output: n_æ_tʰ_tʰ_tʰ_tʰ_tʰ_n_n_n_n_n_n_n_n_n_n_n_n_n_n_n_n_n_n\n",
      "\n",
      "Input:  uə_p_ɹ_ɾ_ɒ_ɴ_l̪\n",
      "Output: p_ɾ_ɾ_ɾ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ\n",
      "\n",
      "Input:  tʂʰ\n",
      "Output: tʂʰ_ɾ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ɒ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ\n",
      "\n",
      "Input:  ɪ_ɕ_ә_ɪ_ŋ\n",
      "Output: ɪ_ɪ_ɕ_ә_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ\n",
      "\n",
      "Input:  m_ʌ_ɪ_ɾ_tɕʰ_ij\n",
      "Output: m_ʌ_m_m_m_m_m_m_m_m_m_m_m_m_m_m_m_m_m_m_m_m_m_m_m\n",
      "\n",
      "Input:  ɑ_ɹ_ɹ̩_t_ɪ_l_ɹ_ɾ_i\n",
      "Output: ɹ_ɹ_ɹ_ɹ_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i\n",
      "\n",
      "Input:  ɴ_ɒ_ŋ\n",
      "Output: ɴ_ɒ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ\n",
      "\n",
      "Input:  uə_a_ɪ_k\n",
      "Output: t̪_a_a_k_k_k_k_k_k_k_k_k_k_ɪ_ɪ_ɪ_ɪ_ɪ_ɪ_ɪ_ɪ_ɪ_ɪ_ɪ_ɪ\n",
      "\n",
      "Input:  ɨ_ʌ_ŋ\n",
      "Output: ɨ_ɨ_ɨ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ_ŋ\n",
      "\n",
      "Input:  f_uə_b̞_ɾʲ_i_ɪ\n",
      "Output: p_uə_uə_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i_i\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "        \n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            encoder_embedding,\n",
    "            max_length=25,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "        \n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"_\".join(input_symbols))\n",
    "            print(\"Output:\", \"_\".join(output_symbols))\n",
    "            print()\n",
    "            \n",
    "            if i_input == 10:\n",
    "                break\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances for evaluation\n",
    "n_eval_utterances = 1000 # 10000 # 1000\n",
    "# eval_sentences = prepared_text[-n_eval_utterances:]  # val sentences\n",
    "# eval_utterances = list(utterances)[-n_eval_utterances:]\n",
    "eval_sentences = prepared_text[:n_eval_utterances]\n",
    "eval_utterances = list(utterances)[:n_eval_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3155/3155 [00:12<00:00, 254.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = eval_sentences\n",
    "# sentences = cur_val_sentences\n",
    "interval_dataset = datasets.SentenceIntervalDataset(\n",
    "    sentences,\n",
    "    text_to_id,\n",
    "    join_char=\"_\"\n",
    "    )\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "eos = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss)\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 106.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL: 23440.4224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Segment\n",
    "\n",
    "# dur_weight = 2.0  # Chorowski\n",
    "dur_weight = 1.0\n",
    "\n",
    "i_item = 0\n",
    "losses = []\n",
    "cur_segmented_sentences = []\n",
    "for i_sentence, intervals in enumerate(tqdm(interval_dataset.intervals)):\n",
    "    \n",
    "    # Costs for segment intervals\n",
    "    costs = np.inf*np.ones(len(intervals))\n",
    "    i_eos = intervals[-1][-1]\n",
    "    for i_seg, interval in enumerate(intervals):\n",
    "        if interval is None:\n",
    "            continue\n",
    "        i_start, i_end = interval\n",
    "        dur = i_end - i_start\n",
    "        assert dur == lengths[i_item]\n",
    "        eos = (i_end == i_eos)  # end-of-sequence\n",
    "        \n",
    "        # Chorowski\n",
    "        costs[i_seg] = (\n",
    "            rnn_losses[i_item]\n",
    "            + dur_weight*neg_chorowski(dur)\n",
    "            )\n",
    "        \n",
    "        # Gamma\n",
    "        costs[i_seg] = (\n",
    "            rnn_losses[i_item]\n",
    "            + dur_weight*neg_log_gamma(dur)\n",
    "            + np.log(np.sum(gamma_cache**dur_weight))\n",
    "            )\n",
    "        \n",
    "#         # Poisson\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + neg_log_poisson(dur)\n",
    "#             )\n",
    "\n",
    "#         # Histogram\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*(neg_log_hist(dur))\n",
    "#             + np.log(np.sum(histogram**dur_weight))\n",
    "#             )\n",
    "    \n",
    "        # Sequence boundary\n",
    "        alpha = 0.9  # 0.3  # 0.9\n",
    "        if eos:\n",
    "            costs[i_seg] += -np.log(alpha)\n",
    "        else:\n",
    "            costs[i_seg] += -np.log(1 - alpha)\n",
    "\n",
    "        # Temp\n",
    "#         if dur > 10 or dur <= 1:\n",
    "#             costs[i_seg] = +np.inf\n",
    "        i_item += 1\n",
    "    \n",
    "    # Viterbi segmentation\n",
    "    n_frames = len(interval_dataset.sentences[i_sentence])\n",
    "    summed_cost, boundaries = viterbi.custom_viterbi(costs, n_frames)\n",
    "    losses.append(summed_cost)\n",
    "    \n",
    "    reference_sentence = sentences[i_sentence]\n",
    "    segmented_sentence = get_segmented_sentence(\n",
    "            interval_dataset.sentences[i_sentence],\n",
    "            boundaries\n",
    "            )\n",
    "    cur_segmented_sentences.append(segmented_sentence)\n",
    "#     # Print examples of the first few sentences\n",
    "#     if i_sentence < 10:\n",
    "#         print(reference_sentence)\n",
    "#         print(segmented_sentence)\n",
    "#         print()\n",
    "    \n",
    "print(\"NLL: {:.4f}\".format(np.sum(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð_ɒ_s̪_tʰ_e ɛ_ʀ ɒ_n_s̪ ɾ_e_ə\n"
     ]
    }
   ],
   "source": [
    "print(cur_segmented_sentences[0])\n",
    "\n",
    "# # To evaluate gold segmentation:\n",
    "# cur_segmented_sentences = prepared_text_gold[:n_eval_utterances]\n",
    "# print(cur_segmented_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 121026.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 27, 'ð_ɒ_s̪_tʰ_e'), (27, 36, 'ɛ_ʀ'), (36, 54, 'ɒ_n_s̪'), (54, 64, 'ɾ_e_ə')]\n",
      "[(0, 19, 'those'), (19, 55, 'parents'), (55, 64, 'were')]\n",
      "\n",
      "[(0, 29, 'ʔ_ɒ')]\n",
      "[(0, 11, 'i'), (11, 29, 'went')]\n",
      "\n",
      "[(0, 9, 'ɴ_ɨ'), (9, 21, 'ə_w_ɒ'), (21, 42, 'e_n_ɴ_uə_a'), (42, 99, 'ɒ_ɳ_ɴ_o_ɪ_e')]\n",
      "[(0, 20, 'no'), (20, 33, 'in'), (33, 57, 'one'), (57, 99, 'week')]\n",
      "\n",
      "[(0, 49, 'None')]\n",
      "[(0, 9, 'when'), (9, 15, 'it'), (15, 42, 'happened'), (42, 49, 'in')]\n",
      "\n",
      "[(0, 12, 'ɾʲ_ə_t̪'), (12, 21, 't_ə'), (21, 36, 'ɕ_uː'), (36, 45, 'ə_ʂ_uə'), (45, 63, 'ʁ_uː_z'), (63, 72, 't_ə'), (72, 90, 'f_a_ɪ'), (90, 103, 't_ə')]\n",
      "[(0, 10, 'it'), (10, 25, 'was'), (25, 59, 'useless'), (59, 69, 'to'), (69, 95, 'fight'), (95, 103, 'it')]\n",
      "\n",
      "[(0, 12, 'ɒ_n_ɳ'), (12, 30, 'n_ɒ_t̪'), (30, 71, 't͡ɕ_o_uə_z')]\n",
      "[(0, 15, 'and'), (15, 31, 'not'), (31, 71, 'just')]\n",
      "\n",
      "[(0, 24, 'k_æ_f'), (24, 42, 't_ə_d'), (42, 60, 'b̥_i_e_ə'), (60, 72, 'b̞_ʌ_ɾ'), (72, 93, 'ə_t_ɹ'), (93, 123, 'ʌ_s_t')]\n",
      "[(0, 24, 'tough'), (24, 37, 'to'), (37, 52, 'be'), (52, 67, 'able'), (67, 74, 'to'), (74, 123, 'trust')]\n",
      "\n",
      "[(0, 21, 's_uə'), (21, 40, 'ʌ_l̪_ɒ_ɳ')]\n",
      "[(0, 40, 'son')]\n",
      "\n",
      "[(0, 12, 'ɴ_ə_ɴ'), (12, 24, 'j_iː_t'), (24, 48, 'ʌ_ə_pʰ_a'), (48, 75, 'p_i_ɪ_ɴ_ɪ'), (75, 90, 'tɕʰ_i_e_n'), (90, 102, 't_iː_ɴ'), (102, 117, 'tʂ_e_g'), (117, 129, 'i_æ_ɒ'), (129, 141, 'ð_ɪ')]\n",
      "[(0, 12, 'gonna'), (12, 24, 'get'), (24, 28, 'a'), (28, 57, 'puppy'), (57, 66, 'and'), (66, 70, 'a'), (70, 100, 'kitten'), (100, 141, 'together')]\n",
      "\n",
      "[(0, 35, 'ij_j_æ')]\n",
      "[(0, 35, 'yet')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert segmentation to intervals\n",
    "segmentation_interval_dict = {}\n",
    "for i_utt, utt_key in tqdm(enumerate(eval_utterances)):\n",
    "    words_segmented = cur_segmented_sentences[i_utt].split(\" \")\n",
    "    word_start = 0\n",
    "    word_label = \"\"\n",
    "    i_word = 0\n",
    "    segmentation_interval_dict[utt_key] = []\n",
    "    for (phone_start, phone_end,\n",
    "            phone_label) in phoneseg_interval_dict[utt_key]:\n",
    "        word_label += phone_label + \"_\"\n",
    "        if words_segmented[i_word] == word_label[:-1]:\n",
    "            segmentation_interval_dict[utt_key].append((\n",
    "                word_start, phone_end, word_label[:-1]\n",
    "                ))\n",
    "            word_label = \"\"\n",
    "            word_start = phone_end\n",
    "            i_word += 1\n",
    "\n",
    "    if i_utt < 10:\n",
    "        print(segmentation_interval_dict[utt_key])\n",
    "        print(word_ref_interval_dict[utt_key])\n",
    "        print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 273476.17it/s]\n",
      "100%|██████████| 16582/16582 [00:00<00:00, 290059.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Word boundaries:\n",
      "Precision: 30.79%\n",
      "Recall: 33.08%\n",
      "F-score: 31.89%\n",
      "OS: 7.44%\n",
      "R-value: 40.04%\n",
      "---------------------------------------------------------------------------\n",
      "Word token boundaries:\n",
      "Precision: 19.61%\n",
      "Recall: 20.64%\n",
      "F-score: 20.11%\n",
      "OS: 5.30%\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Intervals to boundaries\n",
    "segmentation_boundaries_dict = {}\n",
    "for utt_key in tqdm(segmentation_interval_dict):\n",
    "    segmentation_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        segmentation_interval_dict[utt_key]\n",
    "        )\n",
    "word_ref_boundaries_dict = {}\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    word_ref_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        word_ref_interval_dict[utt_key]\n",
    "        )\n",
    "\n",
    "# Evaluate word boundaries\n",
    "reference_list = []\n",
    "segmentation_list = []\n",
    "for utterance in segmentation_boundaries_dict:\n",
    "    reference_list.append(word_ref_boundaries_dict[utterance])\n",
    "    segmentation_list.append(segmentation_boundaries_dict[utterance])\n",
    "\n",
    "tolerance = 2\n",
    "p, r, f = eval_segmentation.score_boundaries(\n",
    "    reference_list, segmentation_list, tolerance=tolerance\n",
    "    )\n",
    "print(\"-\"*(79 - 4))\n",
    "print(\"Word boundaries:\")\n",
    "print(\"Precision: {:.2f}%\".format(p*100))\n",
    "print(\"Recall: {:.2f}%\".format(r*100))\n",
    "print(\"F-score: {:.2f}%\".format(f*100))\n",
    "print(\"OS: {:.2f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "print(\"R-value: {:.2f}%\".format(eval_segmentation.get_rvalue(p, r)*100))\n",
    "print(\"-\"*(79 - 4))\n",
    "\n",
    "p, r, f = eval_segmentation.score_word_token_boundaries(\n",
    "    reference_list, segmentation_list, tolerance=tolerance\n",
    "    )\n",
    "print(\"Word token boundaries:\")\n",
    "print(\"Precision: {:.2f}%\".format(p*100))\n",
    "print(\"Recall: {:.2f}%\".format(r*100))\n",
    "print(\"F-score: {:.2f}%\".format(f*100))\n",
    "print(\"OS: {:.2f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "# print(\"R-value: {:.2f}%\".format(get_rvalue(p, r)*100))\n",
    "print(\"-\"*(79 - 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering_sentences = prepared_text_gold[:10000]\n",
    "# clustering_sentences = prepared_text[:10000]  # probably doesn't make sense\n",
    "clustering_sentences = cur_segmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 576.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3733, 50)\n",
      "2021-08-03 12:33:50.692940\n",
      "Clustering: K = 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_samples=3733 should be >= n_clusters=4096",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5ee735ed575e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Clustering: K = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mvq_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mvq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inertia: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             raise ValueError(\"n_samples=%d should be >= n_clusters=%d\" % (\n\u001b[0m\u001b[1;32m    998\u001b[0m                 _num_samples(X), self.n_clusters))\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_samples=3733 should be >= n_clusters=4096"
     ]
    }
   ],
   "source": [
    "# K-means centroids\n",
    "\n",
    "# Data\n",
    "train_dataset = datasets.WordDataset(\n",
    "    clustering_sentences, text_to_id, n_symbols_max=n_symbols_max\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.eval()\n",
    "encoder_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "        encoder_embeddings.append(encoder_embedding.cpu().numpy())\n",
    "        \n",
    "# Cluster\n",
    "X = np.vstack(encoder_embeddings)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(datetime.now())\n",
    "K = 4096 # 1024  # 1024  # 2048\n",
    "print(\"Clustering: K = {}\".format(K))\n",
    "vq_model = cluster.KMeans(n_clusters=K, max_iter=10)\n",
    "vq_model.fit(X)\n",
    "print(\"Inertia: {:.4f}\".format(vq_model.inertia_))\n",
    "centroids = vq_model.cluster_centers_\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "#     for i_batch, (data, data_lengths) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        encoder_embedding = encoder_embedding.cpu().numpy()\n",
    "        clusters = vq_model.predict(encoder_embedding)\n",
    "        embedding_reconstructed = centroids[clusters, :].reshape(\n",
    "            encoder_embedding.shape\n",
    "            )\n",
    "        embedding_reconstructed = torch.from_numpy(\n",
    "            embedding_reconstructed\n",
    "            ).to(device)\n",
    "        \n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            embedding_reconstructed,\n",
    "            max_length=n_symbols_max,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "        \n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"_\".join(input_symbols))\n",
    "            print(\"Output:\", \"_\".join(output_symbols))\n",
    "            print()\n",
    "            \n",
    "            if i_input == 10:\n",
    "                break\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances for evaluation\n",
    "n_eval_utterances = 1000\n",
    "# eval_sentences = prepared_text[-n_eval_utterances:]  # val sentences\n",
    "# eval_utterances = list(utterances)[-n_eval_utterances:]\n",
    "eval_sentences = prepared_text[:n_eval_utterances]\n",
    "eval_utterances = list(utterances)[:n_eval_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = eval_sentences\n",
    "interval_dataset = datasets.SentenceIntervalDataset(\n",
    "    sentences,\n",
    "    text_to_id,\n",
    "    \"_\"\n",
    "    )\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0  # to-do: adjust this\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        encoder_embedding = encoder_embedding.cpu().numpy()\n",
    "        clusters = vq_model.predict(encoder_embedding)\n",
    "        embedding_reconstructed = centroids[clusters, :].reshape(\n",
    "            encoder_embedding.shape\n",
    "            )\n",
    "        embedding_reconstructed = torch.from_numpy(\n",
    "            embedding_reconstructed\n",
    "            ).to(device)\n",
    "        \n",
    "        decoder_rnn, decoder_output = model.decoder(\n",
    "            embedding_reconstructed, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss)\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options:\n",
    "\n",
    "- Want to evaluate this segmentation: Go back up to the cell where segmentation is done (after segments are embedded).\n",
    "- Want to retrain K-means model based on this segmentation: Go back to start of quantization cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
