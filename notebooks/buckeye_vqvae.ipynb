{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation on Buckeye VQ-VAE Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herman Kamper, 2021\n",
    "\n",
    "Train a segmental autoencoding recurrent neural network (segmental AE-RNN) and perform word segmentation on VQVAE-encoded Buckeye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy.stats import gamma\n",
    "from sklearn import cluster\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from seg_aernn import datasets, models, viterbi\n",
    "from utils import eval_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented_sentence(ids, boundaries):\n",
    "    output = \"\"\n",
    "    cur_word = []\n",
    "    for i_symbol, boundary in enumerate(boundaries):\n",
    "        cur_word.append(id_to_symbol[ids[i_symbol]])\n",
    "        if boundary:\n",
    "            output += \"_\".join(cur_word)\n",
    "            output += \" \"\n",
    "            cur_word = []\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration penalty functions\n",
    "\n",
    "# Histogram\n",
    "histogram = np.array([\n",
    "    0, 1.66322800e-01, 2.35838129e-01, 2.10609187e-01,\n",
    "    1.48025482e-01, 9.42918160e-02, 5.84211098e-02, 3.64679480e-02,\n",
    "    2.18264741e-02, 1.25420784e-02, 7.18500018e-03, 4.27118399e-03,\n",
    "    1.73743077e-03, 1.19448366e-03, 7.42027726e-04, 2.89571796e-04,\n",
    "    2.35277084e-04, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001\n",
    "    ])  # to-do: check this\n",
    "histogram = histogram/np.sum(histogram)\n",
    "def neg_log_hist(dur):\n",
    "    return -np.log(0 if dur >= len(histogram) else histogram[dur])\n",
    "\n",
    "# Cached Gamma\n",
    "shape, loc, scale = (2.3, 0, 1.3)\n",
    "gamma_cache = []\n",
    "for dur in range(200):\n",
    "    gamma_cache.append(gamma.pdf(dur, shape, loc, scale))\n",
    "gamma_cache = np.array(gamma_cache)/np.sum(gamma_cache)\n",
    "def neg_log_gamma(dur):\n",
    "    if dur < 200:\n",
    "        return -np.log(gamma_cache[dur])\n",
    "    else:\n",
    "        return -np.log(0)\n",
    "\n",
    "# Chorowski\n",
    "def neg_chorowski(dur):\n",
    "    return -(dur - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "vq_model = \"vqvae\"\n",
    "dataset = \"buckeye\"\n",
    "split = \"val\"\n",
    "seg_tag = \"phoneseg_dp_penalized\"\n",
    "\n",
    "# Paths\n",
    "seg_dir = (\n",
    "    Path(\"../../../vqwordseg/exp\")/vq_model/dataset/split/seg_tag/\"intervals\"\n",
    "    )\n",
    "word_ref_dir = Path(\"../../../vqwordseg/data\")/dataset/\"word_intervals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2046/16512 [00:00<00:00, 20455.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../../../vqwordseg/exp/vqvae/buckeye/val/phoneseg_dp_penalized/intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16512/16512 [00:00<00:00, 26968.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read phone segmentation\n",
    "phoneseg_interval_dict = {}\n",
    "print(\"Reading: {}\".format(seg_dir))\n",
    "phoneseg_interval_dict = eval_segmentation.get_intervals_from_dir(seg_dir)\n",
    "utterances = phoneseg_interval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16512 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../../../vqwordseg/data/buckeye/word_intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16512/16512 [00:00<00:00, 38498.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read word reference\n",
    "print(\"Reading: {}\".format(word_ref_dir))\n",
    "word_ref_interval_dict = eval_segmentation.get_intervals_from_dir(word_ref_dir, utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16512/16512 [00:00<00:00, 332689.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert intervals to boundaries\n",
    "word_ref_boundaries_dict = {}\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    word_ref_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        word_ref_interval_dict[utt_key]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16512/16512 [00:00<00:00, 870579.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307_343_461_225_435_84_144_125_443_332_42_101_201_202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepared_text = []\n",
    "for utt_key in tqdm(utterances):\n",
    "    prepared_text.append(\n",
    "        \"_\".join([i[2] for i in phoneseg_interval_dict[utt_key]])\n",
    "        )\n",
    "    \n",
    "print(prepared_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16512/16512 [00:00<00:00, 32857.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307_343_461_225 435_84_144_125_443_332_42_101 201_202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gold segmentation, where boundaries are inserted in best possible positions\n",
    "n_not_in_tolerance = 0\n",
    "prepared_text_gold = []\n",
    "for utt_key in tqdm(utterances):\n",
    "    seg_intervals = phoneseg_interval_dict[utt_key].copy()\n",
    "    ref_intervals = word_ref_interval_dict[utt_key].copy()\n",
    "    seg_boundaries = np.array([i[1] - 1 for i in seg_intervals])\n",
    "    ref_boundaries = np.array([i[1] - 1 for i in ref_intervals])\n",
    "    for ref_boundary in ref_boundaries[:-1]:\n",
    "        i_seg = np.argmin(np.abs(seg_boundaries - ref_boundary))\n",
    "        seg_intervals.insert(\n",
    "            i_seg + 1, (seg_intervals[i_seg][1], seg_intervals[i_seg][1], \" \")\n",
    "            )\n",
    "        seg_boundaries = np.array([i[1] - 1 for i in seg_intervals])\n",
    "    cur_text_gold = \"\"\n",
    "    for start, end, label in seg_intervals:\n",
    "        if label == \" \":\n",
    "            cur_text_gold = cur_text_gold[:-1]\n",
    "            cur_text_gold += \" \"\n",
    "        else:\n",
    "            cur_text_gold += label + \"_\"\n",
    "    cur_text_gold = cur_text_gold[:-1]\n",
    "    prepared_text_gold.append(cur_text_gold)\n",
    "\n",
    "print(prepared_text_gold[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[231, 271, 398, 142, 369, 487, 54, 33, 378, 259, 352, 8, 116, 117]\n",
      "['307', '343', '461', '225', '435', '84', '144', '125', '443', '332', '42', '101', '201', '202']\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary\n",
    "PAD_SYMBOL      = \"<pad>\"\n",
    "SOS_SYMBOL      = \"<s>\"    # start of sentence\n",
    "EOS_SYMBOL      = \"</s>\"   # end of sentence\n",
    "BOUNDARY_SYMBOL = \" \"      # word boundary\n",
    "symbols = set()\n",
    "for sentence in prepared_text:\n",
    "    for char in sentence.split(\"_\"):\n",
    "        symbols.add(char)\n",
    "SYMBOLS = [PAD_SYMBOL, SOS_SYMBOL, EOS_SYMBOL, BOUNDARY_SYMBOL] + (sorted(list(symbols)))\n",
    "symbol_to_id = {s: i for i, s in enumerate(SYMBOLS)}\n",
    "id_to_symbol = {i: s for i, s in enumerate(SYMBOLS)}\n",
    "\n",
    "def text_to_id(text, add_sos_eos=False):\n",
    "    \"\"\"\n",
    "    Convert text to a list of symbol IDs.\n",
    "\n",
    "    Sentence start and end symbols can be added by setting `add_sos_eos`.\n",
    "    \"\"\"\n",
    "    symbol_ids = []\n",
    "    for word in text.split(\" \"):\n",
    "        for code in word.split(\"_\"):\n",
    "            symbol_ids.append(symbol_to_id[code])\n",
    "        symbol_ids.append(symbol_to_id[BOUNDARY_SYMBOL])\n",
    "    symbol_ids = symbol_ids[:-1]  # remove last space\n",
    "\n",
    "    if add_sos_eos:\n",
    "        return [symbol_to_id[SOS_SYMBOL]] + symbol_ids + [symbol_to_id[EOS_SYMBOL]]\n",
    "    else:\n",
    "        return symbol_ids\n",
    "\n",
    "print(text_to_id(prepared_text[0]))\n",
    "print([id_to_symbol[i] for i in text_to_id(prepared_text[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307_343_461_225_435_84_144_125_443_332_42_101_201_202\n",
      "231_291_74_51_254\n",
      "246_252_281_144_73_412_234_69_444_277_424_277_446_2\n",
      "444_170_312_483_350_131_461_446\n",
      "86_359_449_225_84_250_452_449_223_139_109_235_210_490_394_461_301\n",
      "2_204_97_436_66_264_150_465_223_488\n",
      "323_432_172_374_215_484_505_205_276_324_87_170_233_430_366_358_450_453_494_213_417_323_213\n"
     ]
    }
   ],
   "source": [
    "# First three words of training data\n",
    "word_dataset = datasets.WordDataset(prepared_text, text_to_id)\n",
    "for i in range(7):\n",
    "    sample = word_dataset[i]\n",
    "    print(\"_\".join([id_to_symbol[i] for i in sample.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. train sentences: 10000\n",
      "Examples: ['307_343_461_225_435_84_144_125_443_332_42_101_201_202', '231_291_74_51_254', '246_252_281_144_73_412_234_69_444_277_424_277_446_2']\n",
      "Min length:  1\n",
      "Max length:  106\n",
      "Mean length: 11.3592\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "# Approximate ground truth (for debugging)\n",
    "# cur_train_sentences = prepared_text_gold[:10000]\n",
    "cur_val_sentences = prepared_text_gold[-1000:]\n",
    "\n",
    "# No boundaries\n",
    "cur_train_sentences = prepared_text[:10000]\n",
    "# cur_val_sentences = prepared_text[-1000:]\n",
    "\n",
    "# Random boundaries\n",
    "np.random.seed(42)\n",
    "# cur_train_sentences = insert_random_boundaries(cur_train_sentences)\n",
    "# cur_val_sentences = insert_random_boundaries(cur_val_sentences)\n",
    "\n",
    "print(\"No. train sentences:\", len(cur_train_sentences))\n",
    "print(\"Examples:\", cur_train_sentences[:3])\n",
    "print(\"Min length: \", min([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Max length: \", max([len(i.split(\"_\")) for i in cur_train_sentences]))\n",
    "print(\"Mean length: {:.4f}\".format(np.mean([len(i.split(\"_\")) for i in cur_train_sentences])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE-RNN model\n",
    "n_symbols = len(SYMBOLS)\n",
    "symbol_embedding_dim = 25  # 25\n",
    "hidden_dim = 500  # 1000  # 200\n",
    "embedding_dim = 150  # 300  # 25\n",
    "teacher_forcing_ratio = 0.5  # 1.0  # 0.5  # 1.0\n",
    "n_encoder_layers = 1  # 1  # 3  # 10\n",
    "n_decoder_layers = 1  # 1\n",
    "batch_size = 32  # 32*3  # 32\n",
    "learning_rate = 0.001\n",
    "input_dropout = 0.0  # 0.5\n",
    "dropout = 0.0\n",
    "n_symbols_max = 25\n",
    "n_epochs_max = 25\n",
    "\n",
    "encoder = models.Encoder(\n",
    "    n_symbols=n_symbols,\n",
    "    symbol_embedding_dim=symbol_embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_encoder_layers,\n",
    "    dropout=dropout,\n",
    "    input_dropout=input_dropout\n",
    "    )\n",
    "decoder = models.Decoder1(\n",
    "    n_symbols=n_symbols,\n",
    "    symbol_embedding_dim=symbol_embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_decoder_layers,\n",
    "    sos_id = symbol_to_id[SOS_SYMBOL],\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "    dropout=dropout\n",
    "    )\n",
    "# decoder = Decoder2(\n",
    "#     n_symbols=n_symbols,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     n_layers=n_decoder_layers,\n",
    "#     dropout=dropout\n",
    "#     )\n",
    "model = models.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 58.955, val loss: 14.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 50.525, val loss: 9.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 45.519, val loss: 8.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 41.384, val loss: 6.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss: 37.725, val loss: 6.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss: 34.620, val loss: 5.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, train loss: 31.914, val loss: 5.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, train loss: 29.568, val loss: 5.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train loss: 27.478, val loss: 5.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, train loss: 25.830, val loss: 5.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train loss: 24.263, val loss: 6.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, train loss: 22.963, val loss: 6.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, train loss: 21.810, val loss: 6.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, train loss: 20.759, val loss: 6.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, train loss: 19.840, val loss: 6.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, train loss: 19.167, val loss: 7.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, train loss: 18.403, val loss: 6.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 52.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, train loss: 17.695, val loss: 6.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 48.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, train loss: 17.027, val loss: 7.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 51.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, train loss: 16.483, val loss: 7.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 52.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, train loss: 16.014, val loss: 7.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 50.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, train loss: 15.669, val loss: 7.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 51.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, train loss: 15.258, val loss: 7.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, train loss: 14.667, val loss: 7.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 52.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, train loss: 14.302, val loss: 7.726\n"
     ]
    }
   ],
   "source": [
    "# Training device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Training data\n",
    "train_dataset = datasets.WordDataset(\n",
    "    cur_train_sentences, text_to_id, n_symbols_max=n_symbols_max\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Validation data\n",
    "val_dataset = datasets.WordDataset(cur_val_sentences, text_to_id)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Loss\n",
    "criterion = nn.NLLLoss(\n",
    "    reduction=\"sum\", ignore_index=symbol_to_id[PAD_SYMBOL]\n",
    "    )\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i_epoch in range(n_epochs_max):\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        optimiser.zero_grad()\n",
    "        data = data.to(device)       \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_output.contiguous().view(-1, decoder_output.size(-1)),\n",
    "            data.contiguous().view(-1)\n",
    "            )\n",
    "        loss /= len(data_lengths)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "            data = data.to(device)            \n",
    "            encoder_embedding, decoder_output = model(\n",
    "                data, data_lengths, data, data_lengths\n",
    "                )\n",
    "\n",
    "            loss = criterion(\n",
    "                decoder_output.contiguous().view(-1,\n",
    "                decoder_output.size(-1)), data.contiguous().view(-1)\n",
    "                )\n",
    "            loss /= len(data_lengths)\n",
    "            val_losses.append(loss.item())\n",
    "    \n",
    "    print(\n",
    "        \"Epoch {}, train loss: {:.3f}, val loss: {:.3f}\".format(\n",
    "        i_epoch,\n",
    "        np.mean(train_losses),\n",
    "        np.mean(val_losses))\n",
    "        )\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  342_213_258_147\n",
      "Output: 342_40_258_147_213_258_147_258_147_258_147_258_147_258_147_258_147_258_222_258_147_258_147_258_222\n",
      "\n",
      "Input:  91_431_10\n",
      "Output: 91_91_431_10_10_151_151_10_151_431_431_151_151_164_148_151_90_277_90_184_117_90_164_148_151\n",
      "\n",
      "Input:  323_317_491_339_144_4_225_88\n",
      "Output: 323_260_491_19_225_88_144_339_144_339_144_339_144_339_144_88_225_144_339_144_88_225_88_144_339\n",
      "\n",
      "Input:  123_109\n",
      "Output: 123_109_109_109_109_109_109_109_109_54_109_293_486_109_109_486_109_320_486_109_486_109_320_486_109\n",
      "\n",
      "Input:  217_246\n",
      "Output: 217_217_246_246_246_246_246_246_246_246_246_246_246_246_246_246_246_246_246_246_246_246_246_246_246\n",
      "\n",
      "Input:  192\n",
      "Output: 192_192_192_192_192_192_192_192_425_158_196_223_425_158_425_196_290_141_468_466_203_21_135_484_353\n",
      "\n",
      "Input:  210_195_118_466_156\n",
      "Output: 210_466_466_156_466_156_466_156_164_156_466_164_24_156_164_192_164_164_156_466_156_164_164_156_164\n",
      "\n",
      "Input:  319_391_463_31_242\n",
      "Output: 391_391_463_242_31_31_463_31_242_31_242_31_242_171_463_31_242_171_171_463_31_242_171_171_242\n",
      "\n",
      "Input:  41_312\n",
      "Output: 41_41_312_312_312_312_385_312_312_385_312_312_385_312_312_385_464_312_385_321_464_312_385_464_312\n",
      "\n",
      "Input:  263\n",
      "Output: 263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263_263\n",
      "\n",
      "Input:  246_449_79\n",
      "Output: 246_312_79_449_79_79_449_79_79_449_449_79_449_449_79_449_79_79_449_79_79_449_79_79_449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "        \n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            encoder_embedding,\n",
    "            max_length=25,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "        \n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"_\".join(input_symbols))\n",
    "            print(\"Output:\", \"_\".join(output_symbols))\n",
    "            print()\n",
    "            \n",
    "            if i_input == 10:\n",
    "                break\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances for evaluation\n",
    "n_eval_utterances = 1000 # 10000 # 1000\n",
    "# eval_sentences = prepared_text[-n_eval_utterances:]  # val sentences\n",
    "# eval_utterances = list(utterances)[-n_eval_utterances:]\n",
    "eval_sentences = prepared_text[:n_eval_utterances]\n",
    "eval_utterances = list(utterances)[:n_eval_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2982/2982 [00:14<00:00, 208.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = eval_sentences\n",
    "# sentences = cur_val_sentences\n",
    "interval_dataset = datasets.SentenceIntervalDataset(\n",
    "    sentences,\n",
    "    text_to_id,\n",
    "    join_char=\"_\"\n",
    "    )\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "eos = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss)\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 161.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL: 11245.1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Segment\n",
    "\n",
    "# dur_weight = 12.0 #  2.5  # 12  # 2.5  # Chorowski\n",
    "dur_weight = 1.0\n",
    "\n",
    "i_item = 0\n",
    "losses = []\n",
    "cur_segmented_sentences = []\n",
    "for i_sentence, intervals in enumerate(tqdm(interval_dataset.intervals)):\n",
    "    \n",
    "    # Costs for segment intervals\n",
    "    costs = np.inf*np.ones(len(intervals))\n",
    "    i_eos = intervals[-1][-1]\n",
    "    for i_seg, interval in enumerate(intervals):\n",
    "        if interval is None:\n",
    "            continue\n",
    "        i_start, i_end = interval\n",
    "        dur = i_end - i_start\n",
    "        assert dur == lengths[i_item]\n",
    "        eos = (i_end == i_eos)  # end-of-sequence\n",
    "        \n",
    "#         # Chorowski\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*neg_chorowski(dur)\n",
    "#             )\n",
    "        \n",
    "#         # Gamma\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*neg_log_gamma(dur)\n",
    "#             + np.log(np.sum(gamma_cache**dur_weight))\n",
    "#             )\n",
    "        \n",
    "#         # Poisson\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + neg_log_poisson(dur)\n",
    "#             )\n",
    "\n",
    "        # Histogram\n",
    "        costs[i_seg] = (\n",
    "            rnn_losses[i_item]\n",
    "            + dur_weight*(neg_log_hist(dur))\n",
    "            + np.log(np.sum(histogram**dur_weight))\n",
    "            )\n",
    "    \n",
    "        # Sequence boundary\n",
    "        alpha = 0.3  # 0.9\n",
    "        if eos:\n",
    "            costs[i_seg] += -np.log(alpha)\n",
    "        else:\n",
    "            costs[i_seg] += -np.log(1 - alpha)\n",
    "\n",
    "        # Temp\n",
    "#         if dur > 10 or dur <= 1:\n",
    "#             costs[i_seg] = +np.inf\n",
    "        i_item += 1\n",
    "    \n",
    "    # Viterbi segmentation\n",
    "    n_frames = len(interval_dataset.sentences[i_sentence])\n",
    "    summed_cost, boundaries = viterbi.custom_viterbi(costs, n_frames)\n",
    "    losses.append(summed_cost)\n",
    "    \n",
    "    reference_sentence = sentences[i_sentence]\n",
    "    segmented_sentence = get_segmented_sentence(\n",
    "            interval_dataset.sentences[i_sentence],\n",
    "            boundaries\n",
    "            )\n",
    "    cur_segmented_sentences.append(segmented_sentence)\n",
    "#     # Print examples of the first few sentences\n",
    "#     if i_sentence < 10:\n",
    "#         print(reference_sentence)\n",
    "#         print(segmented_sentence)\n",
    "#         print()\n",
    "    \n",
    "print(\"NLL: {:.4f}\".format(np.sum(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307_343 461_225 435_84 144_125_443 332 42_101 201_202\n"
     ]
    }
   ],
   "source": [
    "print(cur_segmented_sentences[0])\n",
    "\n",
    "# To evaluate gold segmentation\n",
    "# cur_segmented_sentences = prepared_text_gold[:n_eval_utterances]\n",
    "# print(cur_segmented_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 114087.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 10, '307_343'), (10, 16, '461_225'), (16, 24, '435_84'), (24, 38, '144_125_443'), (38, 44, '332'), (44, 52, '42_101'), (52, 62, '201_202')]\n",
      "[(0, 19, 'those'), (19, 55, 'parents'), (55, 64, 'were')]\n",
      "\n",
      "[(0, 26, '231_291_74_51_254')]\n",
      "[(0, 11, 'i'), (11, 29, 'went')]\n",
      "\n",
      "[(0, 28, '246_252_281_144_73'), (28, 40, '412_234'), (40, 50, '69'), (50, 68, '444_277'), (68, 90, '424_277'), (90, 98, '446_2')]\n",
      "[(0, 20, 'no'), (20, 33, 'in'), (33, 57, 'one'), (57, 99, 'week')]\n",
      "\n",
      "[(0, 48, '444_170_312_483_350_131_461_446')]\n",
      "[(0, 9, 'when'), (9, 15, 'it'), (15, 42, 'happened'), (42, 49, 'in')]\n",
      "\n",
      "[(0, 16, '86_359_449'), (16, 36, '225_84_250'), (36, 56, '452_449_223'), (56, 66, '139_109'), (66, 88, '235_210_490'), (88, 100, '394_461_301')]\n",
      "[(0, 10, 'it'), (10, 25, 'was'), (25, 59, 'useless'), (59, 69, 'to'), (69, 95, 'fight'), (95, 103, 'it')]\n",
      "\n",
      "[(0, 24, '2_204_97_436'), (24, 54, '66_264_150_465'), (54, 70, '223_488')]\n",
      "[(0, 15, 'and'), (15, 31, 'not'), (31, 71, 'just')]\n",
      "\n",
      "[(0, 28, '323_432_172_374_215'), (28, 52, '484_505_205'), (52, 56, '276_324'), (56, 74, '87_170_233'), (74, 90, '430_366_358_450'), (90, 100, '453_494'), (100, 110, '213_417'), (110, 120, '323_213')]\n",
      "[(0, 24, 'tough'), (24, 37, 'to'), (37, 52, 'be'), (52, 67, 'able'), (67, 74, 'to'), (74, 123, 'trust')]\n",
      "\n",
      "[(0, 38, '390_465_386_216_385')]\n",
      "[(0, 40, 'son')]\n",
      "\n",
      "[(0, 16, '96_468_151_447'), (16, 28, '226_394'), (28, 36, '357_305'), (36, 52, '436_500_348_446'), (52, 58, '1'), (58, 70, '180_245'), (70, 88, '390_451_19'), (88, 100, '321_332'), (100, 114, '323_213_447'), (114, 126, '369_70'), (126, 140, '485_214')]\n",
      "[(0, 12, 'gonna'), (12, 24, 'get'), (24, 28, 'a'), (28, 57, 'puppy'), (57, 66, 'and'), (66, 70, 'a'), (70, 100, 'kitten'), (100, 141, 'together')]\n",
      "\n",
      "[(0, 32, '164_95_377_333')]\n",
      "[(0, 35, 'yet')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert segmentation to intervals\n",
    "segmentation_interval_dict = {}\n",
    "for i_utt, utt_key in tqdm(enumerate(eval_utterances)):\n",
    "    words_segmented = cur_segmented_sentences[i_utt].split(\" \")\n",
    "    word_start = 0\n",
    "    word_label = \"\"\n",
    "    i_word = 0\n",
    "    segmentation_interval_dict[utt_key] = []\n",
    "    for (phone_start, phone_end,\n",
    "            phone_label) in phoneseg_interval_dict[utt_key]:\n",
    "        word_label += phone_label + \"_\"\n",
    "        if words_segmented[i_word] == word_label[:-1]:\n",
    "            segmentation_interval_dict[utt_key].append((\n",
    "                word_start, phone_end, word_label[:-1]\n",
    "                ))\n",
    "            word_label = \"\"\n",
    "            word_start = phone_end\n",
    "            i_word += 1\n",
    "\n",
    "    if i_utt < 10:\n",
    "        print(segmentation_interval_dict[utt_key])\n",
    "        print(word_ref_interval_dict[utt_key])\n",
    "        print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 292673.50it/s]\n",
      "100%|██████████| 16512/16512 [00:00<00:00, 310726.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Word boundaries:\n",
      "Precision: 22.52%\n",
      "Recall: 28.55%\n",
      "F-score: 25.18%\n",
      "OS: 26.79%\n",
      "R-value: 27.12%\n",
      "---------------------------------------------------------------------------\n",
      "Word token boundaries:\n",
      "Precision: 13.25%\n",
      "Recall: 15.79%\n",
      "F-score: 14.41%\n",
      "OS: 19.11%\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Intervals to boundaries\n",
    "segmentation_boundaries_dict = {}\n",
    "for utt_key in tqdm(segmentation_interval_dict):\n",
    "    segmentation_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        segmentation_interval_dict[utt_key]\n",
    "        )\n",
    "word_ref_boundaries_dict = {}\n",
    "for utt_key in tqdm(word_ref_interval_dict):\n",
    "    word_ref_boundaries_dict[utt_key] = eval_segmentation.intervals_to_boundaries(\n",
    "        word_ref_interval_dict[utt_key]\n",
    "        )\n",
    "\n",
    "# Evaluate word boundaries\n",
    "reference_list = []\n",
    "segmentation_list = []\n",
    "for utterance in segmentation_boundaries_dict:\n",
    "    reference_list.append(word_ref_boundaries_dict[utterance])\n",
    "    segmentation_list.append(segmentation_boundaries_dict[utterance])\n",
    "\n",
    "tolerance = 2\n",
    "p, r, f = eval_segmentation.score_boundaries(\n",
    "    reference_list, segmentation_list, tolerance=tolerance\n",
    "    )\n",
    "print(\"-\"*(79 - 4))\n",
    "print(\"Word boundaries:\")\n",
    "print(\"Precision: {:.2f}%\".format(p*100))\n",
    "print(\"Recall: {:.2f}%\".format(r*100))\n",
    "print(\"F-score: {:.2f}%\".format(f*100))\n",
    "print(\"OS: {:.2f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "print(\"R-value: {:.2f}%\".format(eval_segmentation.get_rvalue(p, r)*100))\n",
    "print(\"-\"*(79 - 4))\n",
    "\n",
    "p, r, f = eval_segmentation.score_word_token_boundaries(\n",
    "    reference_list, segmentation_list, tolerance=tolerance\n",
    "    )\n",
    "print(\"Word token boundaries:\")\n",
    "print(\"Precision: {:.2f}%\".format(p*100))\n",
    "print(\"Recall: {:.2f}%\".format(r*100))\n",
    "print(\"F-score: {:.2f}%\".format(f*100))\n",
    "print(\"OS: {:.2f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "# print(\"R-value: {:.2f}%\".format(get_rvalue(p, r)*100))\n",
    "print(\"-\"*(79 - 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering_sentences = prepared_text_gold[:10000]\n",
    "clustering_sentences = cur_segmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:00<00:00, 400.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4157, 150)\n",
      "2021-07-26 15:18:19.410862\n",
      "Clustering: K = 1024\n",
      "Inertia: 425332.2500\n",
      "2021-07-26 15:18:41.403616\n"
     ]
    }
   ],
   "source": [
    "# K-means centroids\n",
    "\n",
    "# Data\n",
    "train_dataset = datasets.WordDataset(\n",
    "    clustering_sentences, text_to_id, n_symbols_max=n_symbols_max\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.eval()\n",
    "encoder_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "        encoder_embeddings.append(encoder_embedding.cpu().numpy())\n",
    "        \n",
    "# Cluster\n",
    "X = np.vstack(encoder_embeddings)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(datetime.now())\n",
    "K = 1024  # 1024  # 2048\n",
    "print(\"Clustering: K = {}\".format(K))\n",
    "vq_model = cluster.KMeans(n_clusters=K, max_iter=10)\n",
    "vq_model.fit(X)\n",
    "print(\"Inertia: {:.4f}\".format(vq_model.inertia_))\n",
    "centroids = vq_model.cluster_centers_\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  97\n",
      "Output: 97_97_97_97_97_97_97_97_97_97_97_97_97_97_97_97_97_97_97_97_97_97_97_182_414\n",
      "\n",
      "Input:  476_89_81_225\n",
      "Output: 225_225_225_225_225_225_225_97_225_225_225_232_225_232_225_225_232_225_232_225_225_232_144_232_225\n",
      "\n",
      "Input:  406_282\n",
      "Output: 394_394_394_394_394_394_394_394_394_394_394_394_394_394_394_394_173_321_321_97_394_219_321_394_394\n",
      "\n",
      "Input:  43_210_443_486\n",
      "Output: 486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486_486\n",
      "\n",
      "Input:  449_428_233_429_208_223\n",
      "Output: 208_208_208_263_208_31_263_208_485_208_208_218_97_332_208_245_97_504_208_245_245_208_504_332_97\n",
      "\n",
      "Input:  290_95_433\n",
      "Output: 486_433_433_433_433_433_433_433_433_433_433_449_433_433_433_433_433_449_433_45_433_433_433_449_449\n",
      "\n",
      "Input:  490\n",
      "Output: 21_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490_490\n",
      "\n",
      "Input:  162_346\n",
      "Output: 330_79_79_79_79_79_470_79_79_79_79_79_79_253_79_79_79_79_253_483_79_79_253_79_79\n",
      "\n",
      "Input:  254_272\n",
      "Output: 261_254_319_133_319_319_319_319_319_319_319_319_319_319_319_319_319_319_486_319_319_144_319_486_319\n",
      "\n",
      "Input:  210_357_121_48_443_181_68_72_451\n",
      "Output: 416_416_416_416_416_416_416_416_177_321_416_177_321_416_177_321_416_177_321_321_416_177_321_321_416\n",
      "\n",
      "Input:  115_501_64_375\n",
      "Output: 64_64_64_64_64_64_64_64_203_93_64_185_185_93_64_9_381_64_47_466_164_148_88_144_9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "#     for i_batch, (data, data_lengths) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        encoder_embedding = encoder_embedding.cpu().numpy()\n",
    "        clusters = vq_model.predict(encoder_embedding)\n",
    "        embedding_reconstructed = centroids[clusters, :].reshape(\n",
    "            encoder_embedding.shape\n",
    "            )\n",
    "        embedding_reconstructed = torch.from_numpy(\n",
    "            embedding_reconstructed\n",
    "            ).to(device)\n",
    "        \n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            embedding_reconstructed,\n",
    "            max_length=n_symbols_max,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "        \n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"_\".join(input_symbols))\n",
    "            print(\"Output:\", \"_\".join(output_symbols))\n",
    "            print()\n",
    "            \n",
    "            if i_input == 10:\n",
    "                break\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances for evaluation\n",
    "n_eval_utterances = 1000\n",
    "# eval_sentences = prepared_text[-n_eval_utterances:]  # val sentences\n",
    "# eval_utterances = list(utterances)[-n_eval_utterances:]\n",
    "eval_sentences = prepared_text[:n_eval_utterances]\n",
    "eval_utterances = list(utterances)[:n_eval_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2982/2982 [00:25<00:00, 116.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = eval_sentences\n",
    "interval_dataset = datasets.SentenceIntervalDataset(\n",
    "    sentences,\n",
    "    text_to_id,\n",
    "    \"_\"\n",
    "    )\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0  # to-do: adjust this\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        encoder_embedding = encoder_embedding.cpu().numpy()\n",
    "        clusters = vq_model.predict(encoder_embedding)\n",
    "        embedding_reconstructed = centroids[clusters, :].reshape(\n",
    "            encoder_embedding.shape\n",
    "            )\n",
    "        embedding_reconstructed = torch.from_numpy(\n",
    "            embedding_reconstructed\n",
    "            ).to(device)\n",
    "        \n",
    "        decoder_rnn, decoder_output = model.decoder(\n",
    "            embedding_reconstructed, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss)\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options:\n",
    "\n",
    "- Want to evaluate this segmentation: Go back up to the cell where segmentation is done (after segments are embedded).\n",
    "- Want to retrain K-means model based on this segmentation: Go back to start of quantization cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
