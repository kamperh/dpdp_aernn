{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation on Brent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2021-2022 Herman Kamper, MIT License\n",
    "\n",
    "Train a duration penalized dynamic programming autoencoding recurrent neural network (DPDP AE-RNN) and perform word segmentation on the Brent corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy.stats import gamma\n",
    "from sklearn import cluster\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from dpdp_aernn import datasets, models, viterbi\n",
    "from utils import eval_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented_sentence(ids, boundaries, id_to_symbol, join_char=\"\"):\n",
    "    output = \"\"\n",
    "    cur_word = []\n",
    "    for i_symbol, boundary in enumerate(boundaries):\n",
    "        cur_word.append(id_to_symbol[ids[i_symbol]])\n",
    "        if boundary:\n",
    "            output += join_char.join(cur_word)\n",
    "            output += \" \"\n",
    "            cur_word = []\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration penalty functions\n",
    "\n",
    "# Histogram\n",
    "histogram = np.array([\n",
    "    0., 0.051637, 0.36365634, 0.35984765, 0.1537391,\n",
    "    0.04632681, 0.01662638, 0.00644547, 0.00131839, 0.00040284,\n",
    "    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
    "    0.0001, 0.0001\n",
    "    ])\n",
    "histogram = histogram/np.sum(histogram)\n",
    "def neg_log_hist(dur):\n",
    "    return -np.log(0 if dur >= len(histogram) else histogram[dur])\n",
    "\n",
    "def neg_chorowski(dur):\n",
    "    return -(dur - 1)\n",
    "\n",
    "# Cached Gamma\n",
    "shape, loc, scale = (7, 0, 0.4)\n",
    "gamma_cache = []\n",
    "for dur in range(50):\n",
    "    gamma_cache.append(gamma.pdf(dur, shape, loc, scale))\n",
    "gamma_cache = np.array(gamma_cache)\n",
    "def neg_log_gamma(dur):\n",
    "    if dur < 50:\n",
    "        return -np.log(gamma_cache[dur])\n",
    "    else:\n",
    "        return -np.log(gamma.pdf(dur, shape, loc, scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../data/br-phono.txt\n",
      "No. sentences: 9790\n",
      "\n",
      "Example training sentence reference:\n",
      "yu want tu si D6 bUk\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "fn = Path(\"../data\")/\"br-phono.txt\"\n",
    "print(\"Reading:\", fn)\n",
    "sentences_ref = []\n",
    "with open(fn) as f:\n",
    "    for line in f:\n",
    "        sentences_ref.append(line.strip())\n",
    "print(\"No. sentences:\", len(sentences_ref))\n",
    "train_sentences_ref = sentences_ref[:]\n",
    "val_sentences_ref = sentences_ref[:1000]\n",
    "# test_sentences_ref = sentences_ref[8000:]\n",
    "test_sentences_ref = sentences_ref[:]\n",
    "\n",
    "print(\"\\nExample training sentence reference:\")\n",
    "print(train_sentences_ref[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 48, 3, 50, 30, 42, 47, 3, 47, 48, 3, 46, 38, 3, 15, 11, 3, 31, 27, 39]\n",
      "['y', 'u', ' ', 'w', 'a', 'n', 't', ' ', 't', 'u', ' ', 's', 'i', ' ', 'D', '6', ' ', 'b', 'U', 'k']\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary\n",
    "PAD_SYMBOL = \"<pad>\"\n",
    "SOS_SYMBOL = \"<s>\"    # start of sentence\n",
    "EOS_SYMBOL = \"</s>\"   # end of sentence\n",
    "symbols = set()\n",
    "for sentence in sentences_ref:\n",
    "    for char in sentence:\n",
    "        symbols.add(char)\n",
    "SYMBOLS = [PAD_SYMBOL, SOS_SYMBOL, EOS_SYMBOL] + (sorted(list(symbols)))\n",
    "symbol_to_id = {s: i for i, s in enumerate(SYMBOLS)}\n",
    "id_to_symbol = {i: s for i, s in enumerate(SYMBOLS)}\n",
    "\n",
    "def text_to_id(text, add_sos_eos=False):\n",
    "    \"\"\"\n",
    "    Convert text to a list of symbol IDs.\n",
    "\n",
    "    Sentence start and end symbols can be added by setting `add_sos_eos`.\n",
    "    \"\"\"\n",
    "    symbol_ids = [symbol_to_id[t] for t in text]\n",
    "    if add_sos_eos:\n",
    "        return ([\n",
    "            symbol_to_id[SOS_SYMBOL]] + symbol_ids +\n",
    "            [symbol_to_id[EOS_SYMBOL]\n",
    "            ])\n",
    "    else:\n",
    "        return symbol_ids\n",
    "print(text_to_id(train_sentences_ref[0]))\n",
    "print(\n",
    "    [id_to_symbol[i] for i in  text_to_id(train_sentences_ref[0])]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current train and validation\n",
    "cur_train_sentences = train_sentences_ref\n",
    "cur_val_sentences = val_sentences_ref[:100]\n",
    "cur_train_sentences = [\"\".join(i.split(\" \")) for i in cur_train_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE-RNN model\n",
    "n_symbols = len(SYMBOLS)\n",
    "symbol_embedding_dim = 25\n",
    "hidden_dim = 200\n",
    "embedding_dim = 25\n",
    "teacher_forcing_ratio = 0.5  # 1.0\n",
    "n_encoder_layers = 3  # 2  # 1  # 10\n",
    "n_decoder_layers = 1  # 2  # 1\n",
    "batch_size = 32  # 32\n",
    "learning_rate = 0.001\n",
    "input_dropout = 0.0\n",
    "dropout = 0.0\n",
    "n_epochs_max = 5\n",
    "\n",
    "encoder = models.Encoder(\n",
    "    n_symbols=n_symbols,\n",
    "    symbol_embedding_dim=symbol_embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_encoder_layers,\n",
    "    dropout=dropout,\n",
    "    input_dropout=input_dropout,\n",
    "    )\n",
    "decoder = models.Decoder1(\n",
    "    n_symbols=n_symbols,\n",
    "    symbol_embedding_dim=symbol_embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    n_layers=n_decoder_layers,\n",
    "    sos_id = symbol_to_id[SOS_SYMBOL],\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "    dropout=dropout\n",
    "    )\n",
    "# decoder = models.Decoder2(\n",
    "#     n_symbols=n_symbols,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     n_layers=n_decoder_layers,\n",
    "#     )\n",
    "model = models.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 306/306 [00:05<00:00, 57.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 28.153, val loss: 3.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 306/306 [00:05<00:00, 57.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 21.699, val loss: 1.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 306/306 [00:05<00:00, 57.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 20.097, val loss: 1.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 306/306 [00:05<00:00, 56.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 18.818, val loss: 1.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 306/306 [00:05<00:00, 57.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss: 17.908, val loss: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Training data\n",
    "train_dataset = datasets.WordDataset(cur_train_sentences, text_to_id)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Validation data\n",
    "val_dataset = datasets.WordDataset(cur_val_sentences, text_to_id)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Loss\n",
    "criterion = nn.NLLLoss(\n",
    "    reduction=\"sum\", ignore_index=symbol_to_id[PAD_SYMBOL]\n",
    "    )\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i_epoch in range(n_epochs_max):\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        optimiser.zero_grad()\n",
    "        data = data.to(device)       \n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_output.contiguous().view(-1, decoder_output.size(-1)),\n",
    "            data.contiguous().view(-1)\n",
    "            )\n",
    "        loss /= len(data_lengths)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "            data = data.to(device)            \n",
    "            encoder_embedding, decoder_output = model(\n",
    "                data, data_lengths, data, data_lengths\n",
    "                )\n",
    "\n",
    "            loss = criterion(\n",
    "                decoder_output.contiguous().view(-1,\n",
    "                decoder_output.size(-1)), data.contiguous().view(-1)\n",
    "                )\n",
    "            loss /= len(data_lengths)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"Epoch {}, train loss: {:.3f}, val loss: {:.3f}\".format(\n",
    "        i_epoch,\n",
    "        np.mean(train_losses),\n",
    "        np.mean(val_losses))\n",
    "        )\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "Input:  6\n",
      "Output: 6brASizInD6d%D6dOgiz\n",
      "\n",
      "Input:  It\n",
      "Output: Its6dr&g~d&dizgoINtu\n",
      "\n",
      "Input:  h*\n",
      "Output: hQmEloztusizIts6d%It\n",
      "\n",
      "Input:  D&t\n",
      "Output: D&ts6dOgizn9studidiz\n",
      "\n",
      "Input:  yu\n",
      "Output: yuk&nduItD6d%D6dOgiz\n",
      "\n",
      "Input:  It\n",
      "Output: Its6dr&g~d&dizgoINtu\n",
      "\n",
      "Input:  tek\n",
      "Output: tekItizInD6d%zizIts6\n",
      "\n",
      "Input:  hIm\n",
      "Output: hIz6nADRbUkItItItIts\n",
      "\n",
      "Input:  D6\n",
      "Output: D6b7z6blaksIts6d%Its\n",
      "\n",
      "Input:  pUl\n",
      "Output: pUlItmQtItItItItIts6\n",
      "\n",
      "Input:  yu\n",
      "Output: yuk&nduItD6d%D6dOgiz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "print(\"Examples:\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            encoder_embedding,\n",
    "            max_length=20,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "\n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if (i == symbol_to_id[EOS_SYMBOL] or i ==\n",
    "                        symbol_to_id[PAD_SYMBOL]):\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if (i == symbol_to_id[EOS_SYMBOL] or i ==\n",
    "                        symbol_to_id[PAD_SYMBOL]):\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"\".join(input_symbols))\n",
    "            print(\"Output:\", \"\".join(output_symbols))\n",
    "            print()\n",
    "\n",
    "            if i_input == 10:\n",
    "                break\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1903/1903 [00:07<00:00, 258.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = val_sentences_ref\n",
    "# sentences = test_sentences_ref\n",
    "# sentences = train_sentences_ref\n",
    "interval_dataset = datasets.SentenceIntervalDataset(sentences, text_to_id)\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss)\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                           | 34/1000 [00:00<00:02, 337.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yu want tu si D6 bUk\n",
      "yu want tu si D6 bUk\n",
      "lUk D*z 6 b7 wIT hIz h&t\n",
      "lUk D*z 6b7 wIT hIz h&t\n",
      "&nd 6 dOgi\n",
      "&nd6 dOgi\n",
      "yu want tu lUk &t DIs\n",
      "yu want tu lUk&t DIs\n",
      "lUk &t DIs\n",
      "lUk&t DIs\n",
      "h&v 6 drINk\n",
      "h&v 6d rIN k\n",
      "oke nQ\n",
      "oke nQ\n",
      "WAts DIs\n",
      "WAts DIs\n",
      "WAts D&t\n",
      "WAts D&t\n",
      "WAt Iz It\n",
      "WAt Iz It\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 272.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL: 10198.7362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Segment\n",
    "\n",
    "dur_weight = 1.5\n",
    "\n",
    "i_item = 0\n",
    "predicted_boundaries = []\n",
    "reference_boundaries = []\n",
    "losses = []\n",
    "cur_segmented_sentences = []\n",
    "print(\"Segmenting:\")\n",
    "for i_sentence, intervals in enumerate(tqdm(interval_dataset.intervals)):\n",
    "\n",
    "    # Costs for segment intervals\n",
    "    costs = np.inf*np.ones(len(intervals))\n",
    "    i_eos = intervals[-1][-1]\n",
    "    for i_seg, interval in enumerate(intervals):\n",
    "        if interval is None:\n",
    "            continue\n",
    "        i_start, i_end = interval\n",
    "        dur = i_end - i_start\n",
    "        assert dur == lengths[i_item]\n",
    "        eos = (i_end == i_eos)  # end-of-sequence\n",
    "\n",
    "#         # Chorowski\n",
    "#         costs[i_seg] = (\n",
    "#             rnn_losses[i_item]\n",
    "#             + dur_weight*neg_chorowski(dur)\n",
    "#             )\n",
    "        \n",
    "        # Gamma\n",
    "        costs[i_seg] = (\n",
    "            rnn_losses[i_item]\n",
    "            + dur_weight*neg_log_gamma(dur)\n",
    "            + np.log(np.sum(gamma_cache**dur_weight))\n",
    "            )\n",
    "\n",
    "        # # Histogram\n",
    "        # costs[i_seg] = (\n",
    "        #     rnn_losses[i_item]\n",
    "        #     + dur_weight*(neg_log_hist(dur))\n",
    "        #     + np.log(np.sum(histogram**dur_weight))\n",
    "        #     )\n",
    "\n",
    "#         # Sequence boundary\n",
    "#         alpha = 0.0001  # 0.9\n",
    "#         if eos:\n",
    "#             costs[i_seg] += -np.log(alpha)\n",
    "#         else:\n",
    "#             costs[i_seg] += -np.log(1 - alpha)\n",
    "        \n",
    "        # Sequence boundary\n",
    "        alpha = 0.1 # 0.0001  # 0.9\n",
    "        if eos:\n",
    "            costs[i_seg] += -np.log(alpha)\n",
    "        else:\n",
    "#             costs[i_seg] += -np.log(1 - alpha)\n",
    "            K = 1\n",
    "            costs[i_seg] += -np.log((1 - alpha)/K)\n",
    "\n",
    "        i_item += 1\n",
    "\n",
    "    # Viterbi segmentation\n",
    "    n_frames = len(interval_dataset.sentences[i_sentence])\n",
    "    summed_cost, boundaries = viterbi.custom_viterbi(costs, n_frames)\n",
    "    losses.append(summed_cost)\n",
    "\n",
    "    reference_sentence = sentences[i_sentence]\n",
    "    segmented_sentence = get_segmented_sentence(\n",
    "            interval_dataset.sentences[i_sentence],\n",
    "            boundaries, id_to_symbol\n",
    "            )\n",
    "    cur_segmented_sentences.append(segmented_sentence)\n",
    "    # Print examples of the first few sentences\n",
    "    if i_sentence < 10:\n",
    "        print(reference_sentence)\n",
    "        print(segmented_sentence)\n",
    "        # print()\n",
    "\n",
    "    predicted_boundaries.append(boundaries)\n",
    "    reference_boundaries.append(\n",
    "        datasets.sentence_to_boundaries(reference_sentence)\n",
    "        )\n",
    "\n",
    "print(\"NLL: {:.4f}\\n\".format(np.sum(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Word boundaries:\n",
      "Precision: 81.1819%\n",
      "Recall: 86.7832%\n",
      "F-score: 83.8891%\n",
      "OS: 6.8996%\n",
      "---------------------------------------------------------------------------\n",
      "Word token boundaries:\n",
      "Precision: 71.7956%\n",
      "Recall: 75.2166%\n",
      "F-score: 73.4663%\n",
      "OS: 4.7649%\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "p, r, f  = eval_segmentation.score_boundaries(\n",
    "    reference_boundaries, predicted_boundaries\n",
    "    )\n",
    "print(\"-\"*(79 - 4))\n",
    "print(\"Word boundaries:\")\n",
    "print(\"Precision: {:.4f}%\".format(p*100))\n",
    "print(\"Recall: {:.4f}%\".format(r*100))\n",
    "print(\"F-score: {:.4f}%\".format(f*100))\n",
    "print(\"OS: {:.4f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "print(\"-\"*(79 - 4))\n",
    "\n",
    "p, r, f = eval_segmentation.score_word_token_boundaries(\n",
    "    reference_boundaries, predicted_boundaries\n",
    "    )\n",
    "print(\"Word token boundaries:\")\n",
    "print(\"Precision: {:.4f}%\".format(p*100))\n",
    "print(\"Recall: {:.4f}%\".format(r*100))\n",
    "print(\"F-score: {:.4f}%\".format(f*100))\n",
    "print(\"OS: {:.4f}%\".format(eval_segmentation.get_os(p, r)*100))\n",
    "print(\"-\"*(79 - 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prequant_segmented_sentences = cur_train_sentences\n",
    "prequant_segmented_sentences = cur_segmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 106/106 [00:00<00:00, 540.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3386, 25)\n",
      "2022-02-24 10:48:22.605330\n",
      "Clustering\n",
      "Inertia: 23002.5840\n",
      "2022-02-24 10:48:23.197803\n"
     ]
    }
   ],
   "source": [
    "# Find the K-means centroids\n",
    "\n",
    "# Data\n",
    "sentences = prequant_segmented_sentences\n",
    "train_dataset = datasets.WordDataset(sentences, text_to_id)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=datasets.pad_collate\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.eval()\n",
    "encoder_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "        encoder_embeddings.append(encoder_embedding.cpu().numpy())\n",
    "\n",
    "        \n",
    "# Cluster\n",
    "X = np.vstack(encoder_embeddings)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(datetime.now())\n",
    "print(\"Clustering\")\n",
    "K = 128  # 1024  # 2048\n",
    "vq_model = cluster.KMeans(n_clusters=K, max_iter=10)\n",
    "vq_model.fit(X)\n",
    "print(\"Inertia: {:.4f}\".format(vq_model.inertia_))\n",
    "centroids = vq_model.cluster_centers_\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  h9\n",
      "Output: h9do&tizl9ktusekItiz\n",
      "\n",
      "Input:  lUk\n",
      "Output: lUksekItizIts6mQRzIn\n",
      "\n",
      "Input:  f%\n",
      "Output: f%milizIts6d%Its6vD6\n",
      "\n",
      "Input:  h9\n",
      "Output: h9do&tizl9ktusekItiz\n",
      "\n",
      "Input:  D&t\n",
      "Output: D&ts6dOgizn9studidiz\n",
      "\n",
      "Input:  h9\n",
      "Output: h9do&tizl9ktusekItiz\n",
      "\n",
      "Input:  D&ts\n",
      "Output: D&tsD6dOgizn9studidi\n",
      "\n",
      "Input:  kAm\n",
      "Output: kAmh(mimituIttupUtIt\n",
      "\n",
      "Input:  bAni\n",
      "Output: bAtRzl9kD6dOgiznD6d%\n",
      "\n",
      "Input:  It\n",
      "Output: Its6dr&g~d&dizgoINtu\n",
      "\n",
      "Input:  huz\n",
      "Output: huzInD6d%D6d%zizIts6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples without segmentation\n",
    "\n",
    "# Apply to validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(val_loader):\n",
    "#     for i_batch, (data, data_lengths) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        encoder_embedding = encoder_embedding.cpu().numpy()\n",
    "        clusters = vq_model.predict(encoder_embedding)\n",
    "        embedding_reconstructed = centroids[clusters, :].reshape(\n",
    "            encoder_embedding.shape\n",
    "            )\n",
    "        embedding_reconstructed = torch.from_numpy(\n",
    "            embedding_reconstructed\n",
    "            ).to(device)\n",
    "        \n",
    "        y, log_probs = model.decoder.greedy_decode(\n",
    "            embedding_reconstructed,\n",
    "            max_length=20,\n",
    "            )\n",
    "        x = data.cpu().numpy()\n",
    "        \n",
    "        for i_input in range(y.shape[0]):\n",
    "            # Only print up to EOS symbol\n",
    "            input_symbols = []\n",
    "            for i in x[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                input_symbols.append(id_to_symbol[i])\n",
    "            output_symbols = []\n",
    "            for i in y[i_input]:\n",
    "                if i == symbol_to_id[EOS_SYMBOL] or i == symbol_to_id[PAD_SYMBOL]:\n",
    "                    break\n",
    "                output_symbols.append(id_to_symbol[i])\n",
    "\n",
    "            print(\"Input: \", \"\".join(input_symbols))\n",
    "            print(\"Output:\", \"\".join(output_symbols))\n",
    "            print()\n",
    "            \n",
    "            if i_input == 10:\n",
    "                break\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1903/1903 [00:12<00:00, 146.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed segments\n",
    "\n",
    "# Random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "sentences = train_sentences_ref[:1000]  # to-do: all the sentences\n",
    "# sentences = train_sentences_ref\n",
    "interval_dataset = datasets.SentenceIntervalDataset(sentences, text_to_id)\n",
    "segment_loader = DataLoader(\n",
    "    interval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=datasets.pad_collate,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "# Apply model to data\n",
    "model.decoder.teacher_forcing_ratio = 1.0  # to-do: adjust this\n",
    "model.eval()\n",
    "rnn_losses = []\n",
    "lengths = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, (data, data_lengths) in enumerate(tqdm(segment_loader)):\n",
    "        data = data.to(device)\n",
    "\n",
    "        encoder_embedding, decoder_output = model(\n",
    "            data, data_lengths, data, data_lengths\n",
    "            )\n",
    "\n",
    "        encoder_embedding = encoder_embedding.cpu().numpy()\n",
    "        clusters = vq_model.predict(encoder_embedding)\n",
    "        embedding_reconstructed = centroids[clusters, :].reshape(\n",
    "            encoder_embedding.shape\n",
    "            )\n",
    "        embedding_reconstructed = torch.from_numpy(\n",
    "            embedding_reconstructed\n",
    "            ).to(device)\n",
    "        \n",
    "        decoder_rnn, decoder_output = model.decoder(\n",
    "            embedding_reconstructed, data, data_lengths\n",
    "            )\n",
    "\n",
    "        for i_item in range(data.shape[0]):\n",
    "            item_loss = criterion(\n",
    "                decoder_output[i_item].contiguous().view(-1,\n",
    "                decoder_output[i_item].size(-1)),\n",
    "                data[i_item].contiguous().view(-1)\n",
    "                )\n",
    "            rnn_losses.append(item_loss)\n",
    "            lengths.append(data_lengths[i_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options:\n",
    "- Want to evaluate this segmentation: Go back up to the cell where segmentation is done (after segments are embedded).\n",
    "- Want to retrain K-means model based on this segmentation: Go back to start of quantization cell.\n",
    "- Want to retrain AE-RNN: Run cell below then go back to model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-initialize data and repeat\n",
    "\n",
    "Repeat from AE-RNN pretraining cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create psuedo-sentences and go back to the top cell in this section\n",
    "cur_train_sentences = cur_segmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
